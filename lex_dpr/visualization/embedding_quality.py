# lex_dpr/visualization/embedding_quality.py
"""
ì„ë² ë”© í’ˆì§ˆ ì‹œê°í™” ëª¨ë“ˆ

ì„ë² ë”© í’ˆì§ˆì„ ì¦ëª…í•˜ê³  ì‹œê°í™”í•˜ëŠ” ë‹¤ì–‘í•œ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤:
1. ì„ë² ë”© ê³µê°„ ì‹œê°í™” (t-SNE, UMAP)
2. ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„ (Positive vs Negative)
3. íˆíŠ¸ë§µ ì‹œê°í™”
4. í•™ìŠµ ì „í›„ ë¹„êµ
"""

from __future__ import annotations

import warnings
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.manifold import TSNE

try:
    import umap
    UMAP_AVAILABLE = True
except ImportError:
    UMAP_AVAILABLE = False
    warnings.warn("umap-learnì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. UMAP ì‹œê°í™”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

warnings.filterwarnings("ignore", category=UserWarning)

from lex_dpr.data import load_passages
from lex_dpr.models.encoders import BiEncoder
from lex_dpr.models.templates import TemplateMode, tp, tq
from lex_dpr.utils.io import read_jsonl


def visualize_embedding_space(
    encoder: BiEncoder,
    passages: Dict[str, Dict],
    eval_pairs_path: str,
    output_dir: Path,
    *,
    method: str = "umap",  # "tsne" or "umap"
    n_samples: int = 1000,
    n_components: int = 2,
    random_state: int = 42,
    figsize: Tuple[int, int] = (12, 10),
) -> None:
    """
    ì„ë² ë”© ê³µê°„ì„ 2D/3Dë¡œ ì‹œê°í™”
    
    Args:
        encoder: BiEncoder ëª¨ë¸
        passages: Passage ë”•ì…”ë„ˆë¦¬
        eval_pairs_path: í‰ê°€ ìŒ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        method: ì°¨ì› ì¶•ì†Œ ë°©ë²• ("tsne" or "umap")
        n_samples: ì‹œê°í™”í•  ìƒ˜í”Œ ìˆ˜
        n_components: ì°¨ì› ìˆ˜ (2 or 3)
        random_state: ëœë¤ ì‹œë“œ
        figsize: ê·¸ë¦¼ í¬ê¸°
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # í‰ê°€ ìŒ ë¡œë“œ
    eval_pairs = list(read_jsonl(eval_pairs_path))
    if not eval_pairs:
        print("âš ï¸ í‰ê°€ ìŒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìƒ˜í”Œë§
    if len(eval_pairs) > n_samples:
        indices = np.random.choice(len(eval_pairs), n_samples, replace=False)
        eval_pairs = [eval_pairs[i] for i in indices]
    
    # ì¿¼ë¦¬ì™€ ê´€ë ¨ íŒ¨ì‹œì§€ ì„ë² ë”© ì¶”ì¶œ
    query_texts = []
    query_labels = []
    passage_ids = []
    passage_texts = []
    passage_labels = []
    
    for pair in eval_pairs:
        query_text = pair["query_text"]
        query_texts.append(query_text)
        query_labels.append("Query")
        
        # Positive passages
        positive_ids = pair.get("positive_passages", [])
        for pid in positive_ids[:3]:  # ìµœëŒ€ 3ê°œë§Œ
            if pid in passages:
                passage_ids.append(pid)
                passage_texts.append(passages[pid]["text"])
                passage_labels.append("Positive")
    
    # ì„ë² ë”© ìƒì„±
    print(f"[ì‹œê°í™”] ì„ë² ë”© ìƒì„± ì¤‘... (ì¿¼ë¦¬: {len(query_texts)}, íŒ¨ì‹œì§€: {len(passage_texts)})")
    query_embeddings = encoder.encode_queries(query_texts, batch_size=64)
    passage_embeddings = encoder.encode_passages(passage_texts, batch_size=64)
    
    # í†µí•© ì„ë² ë”©
    all_embeddings = np.vstack([query_embeddings, passage_embeddings])
    all_labels = query_labels + passage_labels
    
    # ì°¨ì› ì¶•ì†Œ
    print(f"[ì‹œê°í™”] {method.upper()}ë¡œ ì°¨ì› ì¶•ì†Œ ì¤‘...")
    if method == "tsne":
        reducer = TSNE(n_components=n_components, random_state=random_state, perplexity=30)
        embeddings_2d = reducer.fit_transform(all_embeddings)
    elif method == "umap":
        if not UMAP_AVAILABLE:
            print("âš ï¸ UMAPì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. t-SNEë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            reducer = TSNE(n_components=n_components, random_state=random_state, perplexity=30)
            embeddings_2d = reducer.fit_transform(all_embeddings)
        else:
            reducer = umap.UMAP(n_components=n_components, random_state=random_state, n_neighbors=15)
            embeddings_2d = reducer.fit_transform(all_embeddings)
    else:
        raise ValueError(f"Unknown method: {method}")
    
    # ì‹œê°í™”
    plt.figure(figsize=figsize)
    sns.set_style("whitegrid")
    
    if n_components == 2:
        # 2D ì‹œê°í™”
        for label in ["Query", "Positive"]:
            mask = np.array(all_labels) == label
            plt.scatter(
                embeddings_2d[mask, 0],
                embeddings_2d[mask, 1],
                label=label,
                alpha=0.6,
                s=50,
            )
        
        plt.xlabel(f"{method.upper()} Component 1", fontsize=12)
        plt.ylabel(f"{method.upper()} Component 2", fontsize=12)
        plt.title(f"ì„ë² ë”© ê³µê°„ ì‹œê°í™” ({method.upper()})", fontsize=14, fontweight="bold")
        plt.legend(fontsize=11)
        plt.tight_layout()
        
        output_path = output_dir / f"embedding_space_{method}.png"
        plt.savefig(output_path, dpi=300, bbox_inches="tight")
        print(f"âœ… ì‹œê°í™” ì €ì¥: {output_path}")
        plt.close()
    
    elif n_components == 3:
        # 3D ì‹œê°í™”
        from mpl_toolkits.mplot3d import Axes3D
        
        fig = plt.figure(figsize=figsize)
        ax = fig.add_subplot(111, projection="3d")
        
        for label in ["Query", "Positive"]:
            mask = np.array(all_labels) == label
            ax.scatter(
                embeddings_2d[mask, 0],
                embeddings_2d[mask, 1],
                embeddings_2d[mask, 2],
                label=label,
                alpha=0.6,
                s=50,
            )
        
        ax.set_xlabel(f"{method.upper()} Component 1", fontsize=12)
        ax.set_ylabel(f"{method.upper()} Component 2", fontsize=12)
        ax.set_zlabel(f"{method.upper()} Component 3", fontsize=12)
        ax.set_title(f"ì„ë² ë”© ê³µê°„ ì‹œê°í™” ({method.upper()}, 3D)", fontsize=14, fontweight="bold")
        ax.legend(fontsize=11)
        
        output_path = output_dir / f"embedding_space_{method}_3d.png"
        plt.savefig(output_path, dpi=300, bbox_inches="tight")
        print(f"âœ… ì‹œê°í™” ì €ì¥: {output_path}")
        plt.close()


def visualize_similarity_distribution(
    encoder: BiEncoder,
    passages: Dict[str, Dict],
    eval_pairs_path: str,
    output_dir: Path,
    *,
    n_samples: int = 500,
    figsize: Tuple[int, int] = (12, 6),
) -> None:
    """
    Positive vs Negative ìœ ì‚¬ë„ ë¶„í¬ ì‹œê°í™”
    
    Args:
        encoder: BiEncoder ëª¨ë¸
        passages: Passage ë”•ì…”ë„ˆë¦¬
        eval_pairs_path: í‰ê°€ ìŒ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        n_samples: ìƒ˜í”Œ ìˆ˜
        figsize: ê·¸ë¦¼ í¬ê¸°
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # í‰ê°€ ìŒ ë¡œë“œ
    eval_pairs = list(read_jsonl(eval_pairs_path))
    if not eval_pairs:
        print("âš ï¸ í‰ê°€ ìŒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìƒ˜í”Œë§
    if len(eval_pairs) > n_samples:
        indices = np.random.choice(len(eval_pairs), n_samples, replace=False)
        eval_pairs = [eval_pairs[i] for i in indices]
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    positive_similarities = []
    negative_similarities = []
    
    print(f"[ì‹œê°í™”] ìœ ì‚¬ë„ ê³„ì‚° ì¤‘... ({len(eval_pairs)}ê°œ ìŒ)")
    corpus_ids = list(passages.keys())
    corpus_texts = [passages[pid]["text"] for pid in corpus_ids]
    
    corpus_embeddings = encoder.encode_passages(corpus_texts, batch_size=64)
    corpus_tensor = np.array(corpus_embeddings)
    
    for pair in eval_pairs:
        query_text = pair["query_text"]
        positive_ids = set(pair.get("positive_passages", []))
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_emb = encoder.encode_queries([query_text], batch_size=1)[0]
        
        # Positive ìœ ì‚¬ë„
        for pid in positive_ids:
            if pid in corpus_ids:
                idx = corpus_ids.index(pid)
                similarity = np.dot(query_emb, corpus_tensor[idx])
                positive_similarities.append(similarity)
        
        # Negative ìœ ì‚¬ë„ (ìƒìœ„ 100ê°œ ì¤‘ positiveê°€ ì•„ë‹Œ ê²ƒë“¤)
        similarities = np.dot(query_emb, corpus_tensor.T)
        top_indices = np.argsort(similarities)[::-1][:100]
        
        for idx in top_indices:
            pid = corpus_ids[idx]
            if pid not in positive_ids:
                negative_similarities.append(similarities[idx])
                if len(negative_similarities) >= len(positive_similarities):
                    break
    
    # ì‹œê°í™”
    plt.figure(figsize=figsize)
    sns.set_style("whitegrid")
    
    plt.hist(
        positive_similarities,
        bins=50,
        alpha=0.7,
        label="Positive",
        color="green",
        density=True,
    )
    plt.hist(
        negative_similarities,
        bins=50,
        alpha=0.7,
        label="Negative",
        color="red",
        density=True,
    )
    
    plt.xlabel("Cosine Similarity", fontsize=12)
    plt.ylabel("Density", fontsize=12)
    plt.title("Positive vs Negative ìœ ì‚¬ë„ ë¶„í¬", fontsize=14, fontweight="bold")
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    pos_mean = np.mean(positive_similarities)
    neg_mean = np.mean(negative_similarities)
    separation = pos_mean - neg_mean
    
    plt.axvline(pos_mean, color="green", linestyle="--", linewidth=2, label=f"Positive í‰ê· : {pos_mean:.3f}")
    plt.axvline(neg_mean, color="red", linestyle="--", linewidth=2, label=f"Negative í‰ê· : {neg_mean:.3f}")
    
    plt.text(
        0.05, 0.95,
        f"ë¶„ë¦¬ë„ (Separation): {separation:.3f}\n"
        f"Positive í‰ê· : {pos_mean:.3f}\n"
        f"Negative í‰ê· : {neg_mean:.3f}",
        transform=plt.gca().transAxes,
        fontsize=10,
        verticalalignment="top",
        bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5),
    )
    
    plt.tight_layout()
    
    output_path = output_dir / "similarity_distribution.png"
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"âœ… ì‹œê°í™” ì €ì¥: {output_path}")
    print(f"   Positive í‰ê· : {pos_mean:.4f}")
    print(f"   Negative í‰ê· : {neg_mean:.4f}")
    print(f"   ë¶„ë¦¬ë„: {separation:.4f}")
    plt.close()


def visualize_similarity_heatmap(
    encoder: BiEncoder,
    passages: Dict[str, Dict],
    eval_pairs_path: str,
    output_dir: Path,
    *,
    n_queries: int = 20,
    n_passages: int = 50,
    figsize: Tuple[int, int] = (14, 10),
) -> None:
    """
    ì¿¼ë¦¬-íŒ¨ì‹œì§€ ìœ ì‚¬ë„ íˆíŠ¸ë§µ ì‹œê°í™”
    
    Args:
        encoder: BiEncoder ëª¨ë¸
        passages: Passage ë”•ì…”ë„ˆë¦¬
        eval_pairs_path: í‰ê°€ ìŒ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        n_queries: ì‹œê°í™”í•  ì¿¼ë¦¬ ìˆ˜
        n_passages: ì‹œê°í™”í•  íŒ¨ì‹œì§€ ìˆ˜
        figsize: ê·¸ë¦¼ í¬ê¸°
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # í‰ê°€ ìŒ ë¡œë“œ
    eval_pairs = list(read_jsonl(eval_pairs_path))
    if not eval_pairs:
        print("âš ï¸ í‰ê°€ ìŒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìƒ˜í”Œë§
    if len(eval_pairs) > n_queries:
        indices = np.random.choice(len(eval_pairs), n_queries, replace=False)
        eval_pairs = [eval_pairs[i] for i in indices]
    
    # ê´€ë ¨ íŒ¨ì‹œì§€ ìˆ˜ì§‘
    all_positive_ids = set()
    for pair in eval_pairs:
        all_positive_ids.update(pair.get("positive_passages", []))
    
    # íŒ¨ì‹œì§€ ìƒ˜í”Œë§
    positive_ids = list(all_positive_ids)[:n_passages]
    if len(positive_ids) < n_passages:
        # ì¶”ê°€ íŒ¨ì‹œì§€ ì„ íƒ
        remaining = n_passages - len(positive_ids)
        other_ids = [pid for pid in passages.keys() if pid not in all_positive_ids]
        if len(other_ids) > remaining:
            other_ids = np.random.choice(other_ids, remaining, replace=False).tolist()
        positive_ids.extend(other_ids)
    
    # ì„ë² ë”© ìƒì„±
    query_texts = [pair["query_text"] for pair in eval_pairs]
    passage_texts = [passages[pid]["text"] for pid in positive_ids]
    
    print(f"[ì‹œê°í™”] ì„ë² ë”© ìƒì„± ì¤‘... (ì¿¼ë¦¬: {len(query_texts)}, íŒ¨ì‹œì§€: {len(passage_texts)})")
    query_embeddings = encoder.encode_queries(query_texts, batch_size=64)
    passage_embeddings = encoder.encode_passages(passage_texts, batch_size=64)
    
    # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
    similarity_matrix = np.dot(query_embeddings, passage_embeddings.T)
    
    # íˆíŠ¸ë§µ ì‹œê°í™”
    plt.figure(figsize=figsize)
    sns.set_style("whitegrid")
    
    # Positive ë§ˆìŠ¤í¬ ìƒì„±
    positive_mask = np.zeros_like(similarity_matrix, dtype=bool)
    for i, pair in enumerate(eval_pairs):
        positive_ids_set = set(pair.get("positive_passages", []))
        for j, pid in enumerate(positive_ids):
            if pid in positive_ids_set:
                positive_mask[i, j] = True
    
    # íˆíŠ¸ë§µ
    sns.heatmap(
        similarity_matrix,
        cmap="YlOrRd",
        annot=False,
        fmt=".2f",
        cbar_kws={"label": "Cosine Similarity"},
        xticklabels=[pid[:20] + "..." if len(pid) > 20 else pid for pid in positive_ids],
        yticklabels=[q[:30] + "..." if len(q) > 30 else q for q in query_texts],
    )
    
    # Positive ì…€ ê°•ì¡°
    for i in range(len(eval_pairs)):
        for j in range(len(positive_ids)):
            if positive_mask[i, j]:
                plt.gca().add_patch(
                    plt.Rectangle((j, i), 1, 1, fill=False, edgecolor="blue", lw=2)
                )
    
    plt.xlabel("Passages", fontsize=12)
    plt.ylabel("Queries", fontsize=12)
    plt.title("ì¿¼ë¦¬-íŒ¨ì‹œì§€ ìœ ì‚¬ë„ íˆíŠ¸ë§µ (íŒŒë€ìƒ‰ í…Œë‘ë¦¬ = Positive)", fontsize=14, fontweight="bold")
    plt.xticks(rotation=45, ha="right")
    plt.yticks(rotation=0)
    plt.tight_layout()
    
    output_path = output_dir / "similarity_heatmap.png"
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"âœ… ì‹œê°í™” ì €ì¥: {output_path}")
    plt.close()


def compare_embeddings_before_after(
    encoder_before: Optional[BiEncoder],
    encoder_after: BiEncoder,
    passages: Dict[str, Dict],
    eval_pairs_path: str,
    output_dir: Path,
    *,
    n_samples: int = 200,
    figsize: Tuple[int, int] = (14, 6),
) -> None:
    """
    í•™ìŠµ ì „í›„ ì„ë² ë”© í’ˆì§ˆ ë¹„êµ
    
    Args:
        encoder_before: í•™ìŠµ ì „ ëª¨ë¸ (Noneì´ë©´ ìŠ¤í‚µ)
        encoder_after: í•™ìŠµ í›„ ëª¨ë¸
        passages: Passage ë”•ì…”ë„ˆë¦¬
        eval_pairs_path: í‰ê°€ ìŒ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        n_samples: ìƒ˜í”Œ ìˆ˜
        figsize: ê·¸ë¦¼ í¬ê¸°
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if encoder_before is None:
        print("âš ï¸ í•™ìŠµ ì „ ëª¨ë¸ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•™ìŠµ í›„ ëª¨ë¸ë§Œ í‰ê°€í•©ë‹ˆë‹¤.")
        visualize_similarity_distribution(encoder_after, passages, eval_pairs_path, output_dir)
        return
    
    # í‰ê°€ ìŒ ë¡œë“œ
    eval_pairs = list(read_jsonl(eval_pairs_path))
    if not eval_pairs:
        print("âš ï¸ í‰ê°€ ìŒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìƒ˜í”Œë§
    if len(eval_pairs) > n_samples:
        indices = np.random.choice(len(eval_pairs), n_samples, replace=False)
        eval_pairs = [eval_pairs[i] for i in indices]
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    def compute_similarities(encoder, pairs):
        positive_sims = []
        negative_sims = []
        
        corpus_ids = list(passages.keys())
        corpus_texts = [passages[pid]["text"] for pid in corpus_ids]
        corpus_embeddings = encoder.encode_passages(corpus_texts, batch_size=64)
        corpus_tensor = np.array(corpus_embeddings)
        
        for pair in pairs:
            query_text = pair["query_text"]
            positive_ids = set(pair.get("positive_passages", []))
            
            query_emb = encoder.encode_queries([query_text], batch_size=1)[0]
            
            # Positive
            for pid in positive_ids:
                if pid in corpus_ids:
                    idx = corpus_ids.index(pid)
                    positive_sims.append(np.dot(query_emb, corpus_tensor[idx]))
            
            # Negative
            similarities = np.dot(query_emb, corpus_tensor.T)
            top_indices = np.argsort(similarities)[::-1][:100]
            
            for idx in top_indices:
                pid = corpus_ids[idx]
                if pid not in positive_ids:
                    negative_sims.append(similarities[idx])
                    if len(negative_sims) >= len(positive_sims):
                        break
        
        return positive_sims, negative_sims
    
    print("[ì‹œê°í™”] í•™ìŠµ ì „ ëª¨ë¸ í‰ê°€ ì¤‘...")
    pos_before, neg_before = compute_similarities(encoder_before, eval_pairs)
    
    print("[ì‹œê°í™”] í•™ìŠµ í›„ ëª¨ë¸ í‰ê°€ ì¤‘...")
    pos_after, neg_after = compute_similarities(encoder_after, eval_pairs)
    
    # ë¹„êµ ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=figsize)
    sns.set_style("whitegrid")
    
    # Before
    axes[0].hist(pos_before, bins=50, alpha=0.7, label="Positive", color="green", density=True)
    axes[0].hist(neg_before, bins=50, alpha=0.7, label="Negative", color="red", density=True)
    axes[0].axvline(np.mean(pos_before), color="green", linestyle="--", linewidth=2)
    axes[0].axvline(np.mean(neg_before), color="red", linestyle="--", linewidth=2)
    axes[0].set_xlabel("Cosine Similarity", fontsize=11)
    axes[0].set_ylabel("Density", fontsize=11)
    axes[0].set_title("í•™ìŠµ ì „", fontsize=12, fontweight="bold")
    axes[0].legend(fontsize=10)
    axes[0].grid(True, alpha=0.3)
    
    # After
    axes[1].hist(pos_after, bins=50, alpha=0.7, label="Positive", color="green", density=True)
    axes[1].hist(neg_after, bins=50, alpha=0.7, label="Negative", color="red", density=True)
    axes[1].axvline(np.mean(pos_after), color="green", linestyle="--", linewidth=2)
    axes[1].axvline(np.mean(neg_after), color="red", linestyle="--", linewidth=2)
    axes[1].set_xlabel("Cosine Similarity", fontsize=11)
    axes[1].set_ylabel("Density", fontsize=11)
    axes[1].set_title("í•™ìŠµ í›„", fontsize=12, fontweight="bold")
    axes[1].legend(fontsize=10)
    axes[1].grid(True, alpha=0.3)
    
    plt.suptitle("í•™ìŠµ ì „í›„ ìœ ì‚¬ë„ ë¶„í¬ ë¹„êµ", fontsize=14, fontweight="bold", y=1.02)
    plt.tight_layout()
    
    output_path = output_dir / "before_after_comparison.png"
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"âœ… ì‹œê°í™” ì €ì¥: {output_path}")
    
    # í†µê³„ ì¶œë ¥
    sep_before = np.mean(pos_before) - np.mean(neg_before)
    sep_after = np.mean(pos_after) - np.mean(neg_after)
    improvement = sep_after - sep_before
    
    print(f"\nğŸ“Š í•™ìŠµ ì „í›„ ë¹„êµ:")
    print(f"   í•™ìŠµ ì „ ë¶„ë¦¬ë„: {sep_before:.4f}")
    print(f"   í•™ìŠµ í›„ ë¶„ë¦¬ë„: {sep_after:.4f}")
    print(f"   ê°œì„ ë„: {improvement:.4f} ({improvement/abs(sep_before)*100:.1f}% ê°œì„ )")
    
    plt.close()

