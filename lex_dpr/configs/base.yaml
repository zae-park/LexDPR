mode: bi
out_dir: checkpoint/lexdpr
seed: 42

trainer:
  epochs: 1
  lr: 2e-5
  use_amp: true
  temperature: 0.05
  eval_pairs: data/pairs_eval.jsonl
  eval_steps: 300
  k: 10
  k_values: [1,3,5,10]
  gradient_accumulation_steps: 8  # 배치 사이즈 1일 때 효과적인 배치 크기 = 1 * 8 = 8
  gradient_checkpointing: false   # PEFT 모델과 호환성 문제로 일단 비활성화

data:
  passages: data/merged_corpus.jsonl
  pairs: data/pairs_train.jsonl
  batches:
    bi: 4              # 메모리 절약: 1로 설정하고 gradient_accumulation_steps 사용
  multiply: 0           # 필요 시 10 같이 키워 샘플 증폭

