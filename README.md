# ğŸ›ï¸ LexDPR  

**ë²•ë ¹, ê·œì •, ë¹„ì¡°ì¹˜ì˜ê²¬ì„œ ë“±ê³¼ ê°™ì€ êµ¬ì¡°í™”ëœ ë¬¸ì„œ**ë¥¼ ëŒ€ìƒìœ¼ë¡œ **Dense Passage Retrieval (DPR)** ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.  
ì¡°ë¬¸Â·í•­Â·í˜¸ ë‹¨ìœ„ì˜ ê³„ì¸µì  êµ¬ì¡°ë¥¼ ê°€ì§„ ë¬¸ì„œì˜ ë¶„í•  ë° ê°€ê³µê³¼ ì˜ë¯¸ì  ì¼ê´€ì„±ì„ ìœ ì§€í•œ ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

---

## ğŸ“˜ ê°œìš”

**ê¸°ì¡´ ìƒìš© ì„ë² ë”© ëª¨ë¸(OpenAI, Cohere, Sentence-Transformers ë“±)ì˜ ë¬¸ì œ:**

- **ê³„ì¸µ êµ¬ì¡°**ê°€ ê¹Šì€ ë¬¸ì„œ(ì¡°/í•­/í˜¸ ë“±)ì— ëŒ€í•œ í‘œí˜„ ë¶€ì¡±  
- **ë²•ë ¹ ë¬¸ë§¥ ì˜ì¡´ì„±**ì´ ë†’ì€ êµ¬ë¬¸ ì²˜ë¦¬ì˜ ë¶ˆì•ˆì •ì„±  
- **ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê²°ëœ ë¬¸ì¥ ê°„ ê±°ë¦¬ ë¬¸ì œ**ë¡œ ì¸í•œ ê²€ìƒ‰ ì •í™•ë„ ì €í•˜  

**LexDPR:**

- ë²•ë ¹ ë¬¸ì„œ êµ¬ì¡°ì— ìµœì í™”ëœ Dense Passage Retrieval íŒŒì´í”„ë¼ì¸
- RAG ì‹œìŠ¤í…œì˜ ì¤‘ê°„ ê²€ìƒ‰ê¸°(retriever) ì—­í•  ìˆ˜í–‰

---

LexDPRì€ ê°œë…ì ìœ¼ë¡œ **ë“€ì–¼ ì¸ì½”ë”(Dual Encoder)** ëª¨ë¸ì…ë‹ˆë‹¤.
ì¦‰, RAG íŒŒì´í”„ë¼ì¸ì˜ ìƒì„±ê¸°(generator)ì™€ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•˜ë©°, **retriever ê³„ì¸µì—ë§Œ ì§‘ì¤‘**í•©ë‹ˆë‹¤.

```
Query Encoder (Sentence-BERT / Legal-BERT)
     â”‚
     â–¼
Query Vector
     â”‚
     â”œâ”€â”€> Passage Encoder (ì¡°ë¬¸/í•­ ë‹¨ìœ„)
     â”‚         â””â”€ êµ¬ì¡°ì  ë‹¨ìœ„ë³„ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì²˜ë¦¬
     â”‚
     â–¼
Similarity Scoring (dot product / cosine)
     â”‚
  Top-k êµ¬ì¡° ë‹¨ìœ„ ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
```

---

## ğŸ§© í”„ë¡œì íŠ¸ êµ¬ì¡° (ìš”ì•½ì•½)

```
ğŸ“ LexDPR/
 â”œâ”€â”€ lex_dpr/                   # íŒ¨í‚¤ì§€ ë©”ì¸ ì½”ë“œ
 â”‚    â”œâ”€â”€ models/               # ëª¨ë¸ ê´€ë ¨ ì½”ë“œ
 â”‚    â”‚   â”œâ”€â”€ encoders.py       # BiEncoder í´ë˜ìŠ¤
 â”‚    â”‚   â”œâ”€â”€ templates.py      # í…œí”Œë¦¿ ëª¨ë“œ
 â”‚    â”‚   â””â”€â”€ config.py         # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
 â”‚    â”œâ”€â”€ cli/                  # CLI ëª…ë ¹ì–´ êµ¬í˜„
 â”‚    â”‚   â”œâ”€â”€ embed.py          # ì„ë² ë”© ìƒì„± ëª…ë ¹ì–´
 â”‚    â”‚   â””â”€â”€ ...
 â”‚    â””â”€â”€ ...
 â”‚
 â”œâ”€â”€ docs/                      # ë¬¸ì„œ
 â”‚    â”œâ”€â”€ TRAINING.md           # ëª¨ë¸ í•™ìŠµ ê°€ì´ë“œ
 â”‚    â””â”€â”€ ...
 â”‚
 â”œâ”€â”€ README.md
 â””â”€â”€ pyproject.toml             # íŒ¨í‚¤ì§€ ì„¤ì •
```

---

## ë¹ ë¥¸ ì‹œì‘

```python
from lex_dpr import BiEncoder
import numpy as np

# ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
encoder = BiEncoder()

# ì§ˆì˜ ì„ë² ë”© ìƒì„±
queries = ["í†µì‹ ê³¼ê¸ˆì„œë¹„ìŠ¤ ë“±ë¡ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"]
query_embeddings = encoder.encode_queries(queries)

# íŒ¨ì‹œì§€ ì„ë² ë”© ìƒì„±
passages = ["1 í†µì‹ ê³¼ê¸ˆì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ë ¤ëŠ” ìëŠ” ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ë°”ì— ë”°ë¼ ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬í•­ì„ ê°–ì¶”ì–´ ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ì¥ê´€ì—ê²Œ ë“±ë¡í•˜ì—¬ì•¼ í•œë‹¤."]
passage_embeddings = encoder.encode_passages(passages)

# ìœ ì‚¬ë„ ê³„ì‚°
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(query_embeddings, passage_embeddings)[0][0]
print(f"ìœ ì‚¬ë„: {similarity:.4f}")
```

---

## ì‚¬ìš© ì˜ˆì‹œ

### 1. Git LFS ì„¤ì •

íŒ¨í‚¤ì§€ì— í¬í•¨ëœ ëª¨ë¸ íŒŒì¼ì€ Git LFSë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤. íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ê¸° ì „ì— Git LFSë¡œ ì‹¤ì œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.

**Git LFS ì„¤ì¹˜:**

```bash
# Red Hat/CentOS ê³„ì—´
sudo yum install -y git-lfs

# Ubuntu/Debian ê³„ì—´
sudo apt-get install -y git-lfs

# Git LFS ì´ˆê¸°í™” (ì²˜ìŒ í•œ ë²ˆë§Œ)
git lfs install
```

**ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ:**

```bash
# ëª¨ë“  LFS íŒŒì¼ ë‹¤ìš´ë¡œë“œ
git lfs pull

# ë˜ëŠ” íŠ¹ì • ë””ë ‰í† ë¦¬ë§Œ ë‹¤ìš´ë¡œë“œ
git lfs pull --include="lex_dpr/models/default_model/**"
```

**íŠ¸ëŸ¬ë¸”ìŠˆíŒ…:**

**`safetensors_rust.SafetensorError: Error while deserializing header: header too large` ì—ëŸ¬:**

ì´ ì—ëŸ¬ëŠ” íŒ¨í‚¤ì§€ì— í¬í•¨ëœ ëª¨ë¸ íŒŒì¼ì´ Git LFS í¬ì¸í„° íŒŒì¼ë¡œë§Œ ì¡´ì¬í•  ë•Œ ë°œìƒí•©ë‹ˆë‹¤.

**í•´ê²° ë°©ë²•:**

1. **Git LFSë¡œ ì‹¤ì œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ:**
   ```bash
   # Git LFS ì„¤ì¹˜ í™•ì¸
   git lfs version
   
   # Git LFS ì´ˆê¸°í™” (ì²˜ìŒ í•œ ë²ˆë§Œ)
   git lfs install
   
   # ì‹¤ì œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
   git lfs pull
   ```

2. **íŠ¹ì • ë””ë ‰í† ë¦¬ë§Œ ë‹¤ìš´ë¡œë“œ:**
   ```bash
   git lfs pull --include="lex_dpr/models/default_model/**"
   ```

3. **LFS íŒŒì¼ í™•ì¸:**
   ```bash
   # LFSë¡œ ì¶”ì ë˜ëŠ” íŒŒì¼ ëª©ë¡ í™•ì¸
   git lfs ls-files
   
   # íŠ¹ì • íŒŒì¼ì´ LFS í¬ì¸í„°ì¸ì§€ í™•ì¸
   head -n 1 lex_dpr/models/default_model/adapter_model.safetensors
   # "version https://git-lfs.github.com/spec/v1"ë¡œ ì‹œì‘í•˜ë©´ í¬ì¸í„° íŒŒì¼
   ```

### 2. ì„ë² ë”© ìƒì„±

#### Python API

**ê¸°ë³¸ ì‚¬ìš© (ê¶Œì¥):**
```python
from lex_dpr import BiEncoder

# ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
encoder = BiEncoder()

# ì§ˆì˜ ì„ë² ë”© ìƒì„±
queries = ["ë²•ë¥  ì§ˆì˜ í…ìŠ¤íŠ¸ 1", "ë²•ë¥  ì§ˆì˜ í…ìŠ¤íŠ¸ 2"]
query_embeddings = encoder.encode_queries(queries, batch_size=64)

# íŒ¨ì‹œì§€ ì„ë² ë”© ìƒì„±
passages = ["ë²•ë¥  ë¬¸ì„œ íŒ¨ì‹œì§€ 1", "ë²•ë¥  ë¬¸ì„œ íŒ¨ì‹œì§€ 2"]
passage_embeddings = encoder.encode_passages(passages, batch_size=64)

# ìœ ì‚¬ë„ ê³„ì‚°
from sklearn.metrics.pairwise import cosine_similarity
similarities = cosine_similarity(query_embeddings, passage_embeddings)
```

**íŠ¹ì • ëª¨ë¸ ê²½ë¡œ ì§€ì •:**
```python
from lex_dpr import BiEncoder, TemplateMode

encoder = BiEncoder(
    "checkpoint/lexdpr/bi_encoder",
    template=TemplateMode.BGE,
    normalize=True,
    max_seq_length=512,
)
```

#### CLI ë°©ì‹

**ì…ë ¥ JSONL íŒŒì¼ í˜•ì‹:**

ê° ì¤„ì€ JSON ê°ì²´ì´ë©°, `id`ì™€ `text` í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ì¶”ê°€ í•„ë“œëŠ” ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤.

**ì§ˆì˜ íŒŒì¼ ì˜ˆì‹œ (`queries.jsonl`):**
```jsonl
{"id": "q1", "text": "í†µì‹ ê³¼ê¸ˆì„œë¹„ìŠ¤ ë“±ë¡ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"}
{"id": "q2", "text": "ì •ë³´í†µì‹ ë§ë²•ìƒ í†µì‹ ê³¼ê¸ˆì„œë¹„ìŠ¤ ì œê³µìì˜ ì˜ë¬´ëŠ”?"}
{"id": "q3", "text": "í†µì‹ ê³¼ê¸ˆì„œë¹„ìŠ¤ ë“±ë¡ ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?"}
```

**íŒ¨ì‹œì§€ íŒŒì¼ ì˜ˆì‹œ (`passages.jsonl`):**
```jsonl
{"id": "LAW_000030_ì œ53ì¡°_â‘ ", "parent_id": "LAW_000030_ì œ53ì¡°", "type": "ë²•ë ¹", "law_id": "000030", "law_name": "ì •ë³´í†µì‹ ë§ ì´ìš©ì´‰ì§„ ë° ì •ë³´ë³´í˜¸ ë“±ì— ê´€í•œ ë²•ë¥ ", "article": "ì œ53ì¡°", "effective_date": "20251001", "text": "1 í†µì‹ ê³¼ê¸ˆì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ë ¤ëŠ” ìëŠ” ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ë°”ì— ë”°ë¼ ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬í•­ì„ ê°–ì¶”ì–´ ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ì¥ê´€ì—ê²Œ ë“±ë¡í•˜ì—¬ì•¼ í•œë‹¤. <ê°œì • 2008.2.29, 2013.3.23, 2017.7.26>"}
{"id": "LAW_000030_ì œ53ì¡°_â‘¡", "parent_id": "LAW_000030_ì œ53ì¡°", "type": "ë²•ë ¹", "law_id": "000030", "law_name": "ì •ë³´í†µì‹ ë§ ì´ìš©ì´‰ì§„ ë° ì •ë³´ë³´í˜¸ ë“±ì— ê´€í•œ ë²•ë¥ ", "article": "ì œ53ì¡°", "effective_date": "20251001", "text": "2 ì œ1í•­ì— ë”°ë¼ ë“±ë¡í•œ ì‚¬í•­ì„ ë³€ê²½í•˜ë ¤ëŠ” ìëŠ” ë³€ê²½ë“±ë¡ì„ í•˜ì—¬ì•¼ í•œë‹¤."}
{"id": "LAW_000030_ì œ54ì¡°_â‘ ", "parent_id": "LAW_000030_ì œ54ì¡°", "type": "ë²•ë ¹", "law_id": "000030", "law_name": "ì •ë³´í†µì‹ ë§ ì´ìš©ì´‰ì§„ ë° ì •ë³´ë³´í˜¸ ë“±ì— ê´€í•œ ë²•ë¥ ", "article": "ì œ54ì¡°", "effective_date": "20251001", "text": "1 í†µì‹ ê³¼ê¸ˆì„œë¹„ìŠ¤ì œê³µìëŠ” ì´ìš©ìì˜ ì§€ê¸‰ì˜ì‚¬ í™•ì¸, ê±°ë˜ë‚´ìš©ì˜ ì¦ë¹™ ë° ë¶„ìŸì¡°ì •ì„ ìœ„í•œ ê¸°ë¡ì„ 5ë…„ê°„ ë³´ê´€í•˜ì—¬ì•¼ í•œë‹¤."}
```

**ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© (ê¶Œì¥):**
```bash
# ì§ˆì˜ ì„ë² ë”© ìƒì„±
lex-dpr embed \
  --model default \
  --input queries.jsonl \
  --outdir embeddings \
  --prefix queries \
  --type query \
  --batch-size 64

# íŒ¨ì‹œì§€ ì„ë² ë”© ìƒì„±
lex-dpr embed \
  --model default \
  --input passages.jsonl \
  --outdir embeddings \
  --prefix passages \
  --type passage \
  --batch-size 64
```

**íŠ¹ì • ëª¨ë¸ ê²½ë¡œ ì§€ì •:**
```bash
# ì§ˆì˜ ì„ë² ë”© ìƒì„±
lex-dpr embed \
  --model checkpoint/lexdpr/bi_encoder \
  --input data/queries.jsonl \
  --outdir embeddings \
  --prefix queries \
  --type query \
  --batch-size 64 \
  --template bge

# íŒ¨ì‹œì§€ ì„ë² ë”© ìƒì„±
lex-dpr embed \
  --model checkpoint/lexdpr/bi_encoder \
  --input data/processed/law_passages.jsonl \
  --outdir embeddings \
  --prefix passages \
  --type passage \
  --batch-size 64 \
  --template bge
```

**ì»¤ìŠ¤í…€ í•„ë“œëª… ì‚¬ìš©:**
```bash
# id í•„ë“œê°€ "doc_id", text í•„ë“œê°€ "content"ì¸ ê²½ìš°
lex-dpr embed \
  --model default \
  --input data.jsonl \
  --outdir embeddings \
  --prefix docs \
  --type passage \
  --id-field doc_id \
  --text-field content
```

**ì¶œë ¥ íŒŒì¼ í˜•ì‹:**
- NPZ í˜•ì‹ (ê¸°ë³¸): `{prefix}.npz` (idsì™€ embeddings í¬í•¨)
- NPY í˜•ì‹: `{prefix}_ids.npy`, `{prefix}_embeds.npy`

#### ìŠ¤í¬ë¦½íŠ¸ ë°©ì‹

```bash
# Python ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰
python scripts/embed_corpus.py \
  --model checkpoint/lexdpr/bi_encoder \
  --input data/queries.jsonl \
  --outdir embeddings \
  --prefix queries \
  --type query
```

---

## ğŸ“„ Model Ablation Study

### ğŸ§© í•œêµ­ì–´ ì „ìš© ë¦¬íŠ¸ë¦¬ë²„ í›„ë³´ (Bi-Encoder)

| í•­ëª©               | **KoSimCSE-roberta-multitask**                               | **KLUE-RoBERTa-base-bi**                               | **KoE5-small**                                             |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------ | ---------------------------------------------------------- |
| **ëª¨ë¸ íƒ€ì…**      | Sentence-BERTí˜• Bi-Encoder                                   | RoBERTa ê¸°ë°˜ Dual Encoder (LexDPRì— ì í•©)              | E5 ê³„ì—´ Encoder (í•œêµ­ì–´ ì „ìš©)                              |
| **íŒŒë¼ë¯¸í„° ìˆ˜**    | â‰ˆ110 M                                                       | â‰ˆ125 M                                                 | â‰ˆ80 M                                                      |
| **í•™ìŠµ ë°©ì‹**      | SimCSE + Multitask (STS, NLI)                                | KLUE íƒœìŠ¤í¬ ê¸°ë°˜ pretrain + contrastive fine-tune ê°€ëŠ¥ | Instruction-style (E5 objective: â€œquery: â€¦â€, â€œpassage: â€¦â€) |
| **ì–¸ì–´ ë²”ìœ„**      | í•œêµ­ì–´ only                                                  | í•œêµ­ì–´ only                                            | í•œêµ­ì–´ only (OpenKoE5)                                     |
| **ì„ë² ë”© í’ˆì§ˆ**    | ì¼ìƒ ë¬¸ì¥, QA, ì§§ì€ ì§ˆì˜ì— ê°•í•¨                              | ë¬¸ì¥ ê¸¸ì´ ì¤‘ê°„~ê¸´ ë²•ë ¹ ë¬¸ì²´ì— ì•ˆì •ì                    | E5 objectiveë¡œ ë¬¸ë§¥ë§¤ì¹­ ì„±ëŠ¥ ìš°ìˆ˜                          |
| **ì¥ì **           | â€¢ ê²½ëŸ‰Â·ë¹ ë¦„<br>â€¢ GPU ë©”ëª¨ë¦¬â†“                                 | â€¢ KLUE í‘œì¤€ ë¬¸ì²´ ì í•©<br>â€¢ íŒŒì¸íŠœë‹ ìš©ì´               | â€¢ ìµœì‹  E5 í”„ë ˆì„ì›Œí¬ êµ¬ì¡°<br>â€¢ cosine ì •ê·œí™” ì•ˆì •          |
| **ì•½ì **           | â€¢ ì „ë¬¸ ë²•ë ¹ ë„ë©”ì¸ ì•½í•¨                                      | â€¢ Pretrained ëª¨ë¸ ê³µê°œ ì ìŒ                            | â€¢ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ê³µê°œ ì²´í¬í¬ì¸íŠ¸                          |
| **ì í•© ì‹œë‚˜ë¦¬ì˜¤**  | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…, ì €ìì› í™˜ê²½                                 | ì¤‘ëŒ€í˜• ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì¶• (LexDPR êµ¬ì¡°ì— ìì—° ì í•©)         | ë„ë©”ì¸ í™•ì¥ ì‹¤í—˜, E5í˜•ì‹ íŒŒì´í”„ë¼ì¸ ì¼ì¹˜                   |
| **LexDPR ì ìš© ì‹œ** | ê·¸ëŒ€ë¡œ `--model BM-K/KoSimCSE-roberta-multitask`ë¡œ í•™ìŠµ ê°€ëŠ¥ | KLUE-RoBERTa-bië¡œ í•™ìŠµ ì‹œ ì¡°ë¬¸/í•­ ë‹¨ìœ„ ì•ˆì •            | `KoE5-small`ì€ E5 prefix(`query:`, `passage:`) ìœ ì§€ í•„ìš”   |


### ğŸ§© í•œêµ­ì–´ ì „ìš© ë¦¬ë­ì»¤ í›„ë³´ (Cross-Encoder)

| í•­ëª©               | **KLUE-RoBERTa-large (Cross-Encoder)**                             | **KR-ELECTRA-discriminator**                          |
| ------------------ | ------------------------------------------------------------------ | ----------------------------------------------------- |
| **ëª¨ë¸ íƒ€ì…**      | Transformer Cross-Encoder                                          | ELECTRA ê¸°ë°˜ Cross-Encoder                            |
| **íŒŒë¼ë¯¸í„° ìˆ˜**    | â‰ˆ355 M                                                             | â‰ˆ110 M                                                |
| **í•™ìŠµ ë°©ì‹**      | (q,p) ìŒ ì…ë ¥ â†’ relevance classification                           | (q,p) ìŒ ì…ë ¥ â†’ relevance classification              |
| **ì–¸ì–´ ë²”ìœ„**      | í•œêµ­ì–´ only                                                        | í•œêµ­ì–´ only                                           |
| **íŠ¹ì§•**           | RoBERTa ê¸°ë°˜ ë¬¸ë§¥ ì´í•´ ê°•ë ¥, ê¸´ ë¬¸ì¥ì—ë„ ì•ˆì •                      | ì—°ì‚° ê°€ë³ê³  í•™ìŠµ ì†ë„ ë¹ ë¦„                            |
| **ì¥ì **           | â€¢ ë†’ì€ ì •ë°€ë„(Top-10 rerank ì„±ëŠ¥) <br>â€¢ ë¬¸ì¥ ê¸¸ì´ ê¸´ ë²•ë ¹ì—ë„ ì í•© | â€¢ ê²½ëŸ‰, ë¹ ë¥¸ ì¬ë­í¬ â€¢ GPU ìì› ì ˆì•½                   |
| **ì•½ì **           | â€¢ ì§€ì—°ì‹œê°„Â·ë©”ëª¨ë¦¬â†‘                                                 | â€¢ ì„¸ë°€í•œ ë…¼ë¦¬ ê´€ê³„ íŒŒì•… í•œê³„                          |
| **ì í•© ì‹œë‚˜ë¦¬ì˜¤**  | ì˜¤í”„ë¼ì¸ ì¸ë±ìŠ¤ ì¬ë­í¬, ì¤‘ìš” ì§ˆì˜ ì •ë°€ í‰ê°€                        | ì‹¤ì‹œê°„ QA, ì €ìì› í™˜ê²½                                |
| **LexDPR ì ìš© ì‹œ** | `bge-reranker-large` ëŒ€ì²´ë¡œ ì‚¬ìš© ê°€ëŠ¥ (ì…ë ¥: [CLS] q [SEP] p)      | ì†Œê·œëª¨ ì‹¤ì‹œê°„ ì¬ë­í¬ê¸° or lightweight rerankerë¡œ ì í•© |


### ğŸ” ì¡°í•©

| ëª©ì                                | ë¦¬íŠ¸ë¦¬ë²„            | ë¦¬ë­ì»¤                 | ì½”ë©˜íŠ¸                                             |
| ---------------------------------- | ------------------- | ---------------------- | -------------------------------------------------- |
| **ì •ë°€ë„ ì¤‘ì‹¬ (ë²•ë ¹ ê²€ìƒ‰ í’ˆì§ˆ â†‘)** | **KLUE-RoBERTa-bi** | **KLUE-RoBERTa-large** | LexDPRì˜ ê¸°ë³¸ DPR êµ¬ì¡°ì™€ ì™„ë²½ í˜¸í™˜, ë²•ë ¹ ë¬¸ì²´ ì•ˆì • |
| **ê²½ëŸ‰Â·ë¹ ë¥¸ ê²€ìƒ‰**                 | **KoSimCSE**        | **KR-ELECTRA**         | ì‹¤ì‹œê°„ ì§ˆì˜ ì‘ë‹µìš©, ë¹ ë¥¸ inference                 |
| **í™•ì¥í˜•(Instruction ê¸°ë°˜)**       | **KoE5-small**      | **KLUE-RoBERTa-large** | E5 í¬ë§· ìœ ì§€ë¡œ multilingual E5-mistral ì „í™˜ ìš©ì´   |


**! 2ë²ˆ (KoSimCSE+KR-ELECTRA)** ì´í›„ **1ë²ˆ (KLUE-RoBERTa-bi+KLUE-RoBERTa-large)**


