# ğŸ›ï¸ LexDPR  
**êµ¬ì¡°í™”ë˜ê³  ê³„ì¸µì ì¸ ë²•ë ¹ ë° ê·œë²” ë¬¸ì„œë¥¼ ìœ„í•œ Dense Passage Retrieval ëª¨ë¸**

LexDPRì€ **ë²•ë ¹, ê·œì •, ë¹„ì¡°ì¹˜ì˜ê²¬ì„œ ë“±ê³¼ ê°™ì€ êµ¬ì¡°í™”ëœ ë¬¸ì„œ**ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” **Dense Passage Retrieval (DPR)** ëª¨ë¸ì…ë‹ˆë‹¤.  
ì¡°Â·í•­Â·í˜¸ ë‹¨ìœ„ì˜ ê³„ì¸µì  êµ¬ì¡°ë¥¼ ê°€ì§„ ë¬¸ì„œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¸ë±ì‹±í•˜ê³ , ì˜ë¯¸ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ë©° ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

---

## ğŸ“˜ í”„ë¡œì íŠ¸ ê°œìš”

ê¸°ì¡´ì˜ ìƒìš© ì„ë² ë”© ëª¨ë¸(OpenAI, Cohere, Sentence-Transformers ë“±)ì€ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œë¥¼ ê°€ì§‘ë‹ˆë‹¤:

- **ê³„ì¸µ êµ¬ì¡°**ê°€ ê¹Šì€ ë¬¸ì„œ(ì¡°/í•­/í˜¸ ë“±)ì— ëŒ€í•œ í‘œí˜„ ë¶€ì¡±  
- **ë²•ë ¹ ë¬¸ë§¥ ì˜ì¡´ì„±**ì´ ë†’ì€ êµ¬ë¬¸ ì²˜ë¦¬ì˜ ë¶ˆì•ˆì •ì„±  
- **ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê²°ëœ ë¬¸ì¥ ê°„ ê±°ë¦¬ ë¬¸ì œ**ë¡œ ì¸í•œ ê²€ìƒ‰ ì •í™•ë„ ì €í•˜  

LexDPRì€ **ë²•ë ¹ ë¬¸ì„œ êµ¬ì¡°ì— ìµœì í™”ëœ Dense Passage Retrieval íŒŒì´í”„ë¼ì¸**ìœ¼ë¡œ, **RAG ì‹œìŠ¤í…œì˜ ì¤‘ê°„ ê²€ìƒ‰ê¸°(retriever)** ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

---

## âš™ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

LexDPRì€ êµ¬ì¡° ì¸ì‹í˜•(Dense Passage Retrieval with structure-awareness) **ë“€ì–¼ ì¸ì½”ë”(Dual Encoder)** ëª¨ë¸ì…ë‹ˆë‹¤.

```
Query Encoder (Sentence-BERT / Legal-BERT)
     â”‚
     â–¼
Query Vector
     â”‚
     â”œâ”€â”€> Passage Encoder (ì¡°ë¬¸/í•­ ë‹¨ìœ„)
     â”‚         â””â”€ êµ¬ì¡°ì  ë‹¨ìœ„ë³„ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì²˜ë¦¬
     â”‚
     â–¼
Similarity Scoring (dot product / cosine)
     â”‚
  Top-k êµ¬ì¡° ë‹¨ìœ„ ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
```

LexDPRì€ RAG íŒŒì´í”„ë¼ì¸ì˜ ìƒì„±ê¸°(generator)ì™€ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•˜ë©°, **retriever ê³„ì¸µì—ë§Œ ì§‘ì¤‘**í•©ë‹ˆë‹¤.

---

## ğŸ§© í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ğŸ“ LexDPR/
 â”œâ”€â”€ data/
 â”‚    â”œâ”€â”€ statutes/             # ë²•ë ¹ ë¬¸ì„œ (ì¡°/í•­/í˜¸ ë‹¨ìœ„)
 â”‚    â”œâ”€â”€ no_action_letters/    # ë¹„ì¡°ì¹˜ì˜ê²¬ì„œ ë°ì´í„°
 â”‚    â”œâ”€â”€ queries/              # ì§ˆì˜ ë°ì´í„° (JSONL)
 â”‚    â””â”€â”€ processed/            # ì „ì²˜ë¦¬ í›„ corpus.jsonl
 â”‚
 â”œâ”€â”€ scripts/
 â”‚    â”œâ”€â”€ preprocess_acts.py    # ë²•ë ¹ ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ì²­í¬ ìƒì„±
 â”‚    â”œâ”€â”€ encode_passages.py    # íŒ¨ì‹œì§€ ì„ë² ë”© ìƒì„±
 â”‚    â”œâ”€â”€ encode_queries.py     # ì§ˆì˜ ì„ë² ë”© ìƒì„±
 â”‚    â”œâ”€â”€ build_index.py        # FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
 â”‚    â””â”€â”€ evaluate.py           # í‰ê°€ (Recall@k ë“±)
 â”‚
 â”œâ”€â”€ configs/
 â”‚    â”œâ”€â”€ base.yaml             # ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
 â”‚    â”œâ”€â”€ model.yaml            # ì¸ì½”ë” ì•„í‚¤í…ì²˜ ì„¤ì •
 â”‚    â””â”€â”€ data.yaml             # ë°ì´í„° ê²½ë¡œ ë° ì „ì²˜ë¦¬ ì˜µì…˜
 â”‚
 â”œâ”€â”€ run_demo_real.sh           # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
 â”œâ”€â”€ README.md
 â””â”€â”€ requirements.txt
```

---

## ğŸ” ì£¼ìš” ê¸°ëŠ¥

- **ì‹¤ì œ Sentence-Transformers ê¸°ë°˜ DPR ì¸ì½”ë” ì‚¬ìš©**  
  `sentence-transformers/all-MiniLM-L6-v2` ê¸°ë°˜ ì¸ì½”ë”© (í•„ìš” ì‹œ Legal-BERT êµì²´ ê°€ëŠ¥)
- **êµ¬ì¡° ì¸ì‹í˜• ì²­í¬ ë¶„í• **  
  ì¡°ë¬¸Â·í•­ ë‹¨ìœ„ì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ ë¶„ì„í•´ ë¬¸ë§¥ ë‹¨ìœ„ë³„ë¡œ ì„¸ë¶„í™”
- **FAISS ê¸°ë°˜ ë²¡í„° ì¸ë±ì‹±**  
  ëŒ€ìš©ëŸ‰ ë²•ë ¹ ë°ì´í„°ì˜ íš¨ìœ¨ì  ê²€ìƒ‰
- **Recall@k í‰ê°€ ìë™í™”**  
  `data/queries/queries.jsonl`ì˜ positive passage ê¸°ì¤€ìœ¼ë¡œ ì •í™•ë„ í‰ê°€
- **ê°„ë‹¨í•œ ì‹¤í–‰**  
  `run_demo_real.sh` í•˜ë‚˜ë¡œ ì „ì²˜ë¦¬â†’ì„ë² ë”©â†’ì¸ë±ìŠ¤â†’í‰ê°€ ì¼ê´„ ìˆ˜í–‰

---

## ğŸ§  í™œìš© ë¶„ì•¼

- ë²•ë ¹ ë° ê·œì œ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ  
- ë¹„ì¡°ì¹˜ì˜ê²¬ì„œ / í–‰ì •í•´ì„ ì§ˆì˜ì‘ë‹µ ê²€ìƒ‰  
- ê·œì œ ì¤€ìˆ˜(Compliance) ìë™í™” ë„êµ¬  
- ê³„ì•½ì„œ / ì •ì±… / ê·œì • ê¸°ë°˜ QA RAG ì‹œìŠ¤í…œ  

---

## ì‚¬ìš© ì˜ˆì‹œ

```bash
# 1. ì˜ì¡´ì„± ì„¤ì¹˜ (Poetry íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €)
poetry install

# ì›¹ ë¡œê¹… ì„œë¹„ìŠ¤ ì‚¬ìš© ì‹œ (ì„ íƒì‚¬í•­)
# ëª¨ë“  ì›¹ ë¡œê¹… ì„œë¹„ìŠ¤ ì„¤ì¹˜:
poetry install --extras "web-logging"
# ë˜ëŠ” ê°œë³„ ì„œë¹„ìŠ¤ë§Œ ì„¤ì¹˜:
poetry install --extras "wandb"      # WandBë§Œ
poetry install --extras "mlflow"     # MLflowë§Œ
# ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ë™ì‹œ ì„¤ì¹˜:
poetry install --extras "wandb mlflow"

# ê°œë°œ ì‹œ (ì›¹ ë¡œê¹… ì„œë¹„ìŠ¤ í¬í•¨í•˜ì—¬ ê°œë°œ)
# ë°©ë²• 1: extras ì‚¬ìš©
poetry install --extras "web-logging"
# ë°©ë²• 2: ê°œë°œ ê·¸ë£¹ê³¼ í•¨ê»˜ ì„¤ì¹˜ (í–¥í›„ ì¶”ê°€ ì˜ˆì •)
# poetry install --with dev

# 1-1. ì„¤ì¹˜ í™•ì¸
# íŒ¨í‚¤ì§€ê°€ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸:
python -c "from lex_dpr import BiEncoder, TemplateMode; print('âœ… ì„¤ì¹˜ ì„±ê³µ')"

# ë˜ëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:
python test_embedding_import.py

# 2. ì„¤ì • íŒŒì¼ ì´ˆê¸°í™”
poetry run lex-dpr config init

# ============================================
# ğŸ“Œ í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì • ê°€ì´ë“œ (ì²˜ìŒ cloneí•œ ê²½ìš°)
# ============================================
# 
# í”„ë¡œì íŠ¸ë¥¼ ì²˜ìŒ cloneí•œ ê²½ìš°, ë‹¤ìŒ ìˆœì„œë¡œ ë°ì´í„°ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤:
#
# 1. ì›ë³¸ ë°ì´í„° í™•ì¸
#    - data/laws/          : ë²•ë ¹ JSON íŒŒì¼ë“¤
#    - data/admin_rules/   : í–‰ì •ê·œì¹™ JSON íŒŒì¼ë“¤
#    - data/precedents/    : íŒë¡€ JSON íŒŒì¼ë“¤ (ì´ë¯¸ ìˆì„ ìˆ˜ ìˆìŒ)
#
# 2. Passage ìƒì„± (ì „ì²˜ë¦¬)
#    ë²•ë ¹, í–‰ì •ê·œì¹™, íŒë¡€ JSONì„ passage JSONLë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
#    (preprocess_auto.pyëŠ” ìë™ìœ¼ë¡œ íŒŒì¼ íƒ€ì…ì„ ê°ì§€í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤)
#
# ============================================
# ğŸ“Œ Passage ë¶„í•  ë‹¨ìœ„ ì„¤ëª…
# ============================================
# 
# ê° ë°ì´í„° íƒ€ì…ì€ êµ¬ì¡°ì  íŠ¹ì„±ì— ë”°ë¼ ë‹¤ë¥¸ ë‹¨ìœ„ë¡œ ë¶„í• ë©ë‹ˆë‹¤:
#
# 1. ë²•ë ¹ (í•­ ë‹¨ìœ„):
#    - êµ¬ì¡°í™”ëœ ê³„ì¸µ êµ¬ì¡°(ì¡°ë¬¸ â†’ í•­ â†’ í˜¸)ê°€ ëª…í™•í•¨
#    - í•­(paragraph) ë‹¨ìœ„ë¡œ passage ìƒì„± (ê¸°ë³¸ê°’)
#    - í˜¸(ì ˆ)ê°€ ìˆìœ¼ë©´ í•­ ë‚´ìš©ê³¼ í˜¸ë“¤ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ passageë¡œ ìƒì„±
#    - ì˜ˆ: "LAW_000030_ì œ2ì¡°_â‘ " (ì œ2ì¡° ì œ1í•­)
#    - í˜¸ ë‹¨ìœ„ê¹Œì§€ ì„¸ë¶„í™”í•˜ë ¤ë©´ --include-items í”Œë˜ê·¸ ì‚¬ìš©
#
# 2. í–‰ì •ê·œì¹™ (ì¡°ë¬¸ ë‹¨ìœ„):
#    - í•­/í˜¸ êµ¬ì¡° ì •ë³´ê°€ ì—†ê±°ë‚˜ ëœ ëª…í™•í•¨
#    - ì¡°ë¬¸(article) ë‹¨ìœ„ë¡œ passage ìƒì„±
#    - ì˜ˆ: "ADM_2200000106255_ì œ54ì¡°" (ì œ54ì¡° ì „ì²´)
#
# 3. íŒë¡€ (ì²­í¬ ë‹¨ìœ„):
#    - êµ¬ì¡°í™”ëœ ê³„ì¸µ êµ¬ì¡°ê°€ ì—†ìŒ
#    - íŒê²°ë³¸ë¬¸ì„ ê¸¸ì´ ê¸°ë°˜ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì²­í¬ ë¶„í• 
#    - ê¸°ë³¸ê°’: ìµœëŒ€ 1200ì, ì˜¤ë²„ë© 200ì
#    - ì˜ˆ: "PREC_094864_1", "PREC_094864_2" (ê°™ì€ íŒë¡€ì˜ ì—¬ëŸ¬ ì²­í¬)
#
poetry run python -m lex_dpr.data_processing.preprocess_auto \
  --src-dir data/laws \
  --out-law data/processed/law_passages.jsonl \
  --glob "**/*.json"

poetry run python -m lex_dpr.data_processing.preprocess_auto \
  --src-dir data/admin_rules \
  --out-admin data/processed/admin_passages.jsonl \
  --glob "**/*.json"

poetry run python -m lex_dpr.data_processing.preprocess_auto \
  --src-dir data/precedents \
  --out-prec data/processed/prec_passages.jsonl \
  --glob "**/*.json"

# ë²•ë ¹ì„ í˜¸ ë‹¨ìœ„ê¹Œì§€ ì„¸ë¶„í™”í•˜ë ¤ë©´ (ì„ íƒì‚¬í•­):
# poetry run python -m lex_dpr.data_processing.preprocess_auto \
#   --src-dir data/laws \
#   --out-law data/processed/law_passages.jsonl \
#   --glob "**/*.json" \
#   --include-items  # í˜¸(ì ˆ) ë‹¨ìœ„ê¹Œì§€ ìƒì„±

# 3. Passage ì½”í¼ìŠ¤ ë³‘í•© (ì„ íƒì‚¬í•­, í‰ê°€ìš©)
#    ë²•ë ¹ê³¼ í–‰ì •ê·œì¹™ passageë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
poetry run python -m lex_dpr.data_processing.merge_corpus \
  --law data/processed/law_passages.jsonl \
  --admin data/processed/admin_passages.jsonl \
  --out data/processed/merged_corpus.jsonl

# 4. ì§ˆì˜-passage ìŒ ìƒì„± (train/valid/test split í¬í•¨)
#    - law/admin/precedent passageë¥¼ ì´ìš©í•´ pairs_train/valid/testë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
#    - íŒë¡€ ì›ë³¸ JSON ë””ë ‰í† ë¦¬ë¥¼ ì§ì ‘ ì§€ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ (--prec-json-dir)
#
# ============================================
# ğŸ“Œ íŒë¡€ ë°ì´í„° ì²˜ë¦¬ ë°©ì‹
# ============================================
# 
# íŒë¡€ëŠ” ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤:
#
# 1. ìš°ì„ ìˆœìœ„: ì°¸ì¡°ì¡°ë¬¸ì—ì„œ ë²•ë ¹/í–‰ì •ê·œì¹™ ë§¤ì¹­
#    - íŒë¡€ JSONì˜ "ì°¸ì¡°ì¡°ë¬¸" í•„ë“œì—ì„œ ë²•ë ¹/í–‰ì •ê·œì¹™ì„ íŒŒì‹±
#    - ì˜ˆ: "[1]í˜•ë²• ì œ355ì¡° ì œ1í•­,ì œ356ì¡° / [2]ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì— ê´€í•œ ê·œì¹™ ì œ1ì¡°"
#    - íŒŒì‹±í•œ ë²•ë ¹/í–‰ì •ê·œì¹™ì„ ì¸ë±ìŠ¤ì—ì„œ ì°¾ì•„ positive passageë¡œ ì‚¬ìš©
#    - ì§ˆì˜: íŒì‹œì‚¬í•­/íŒê²°ìš”ì§€ ê¸°ë°˜ ìƒì„±
#    - Positive: ì°¸ì¡°ì¡°ë¬¸ì—ì„œ ë§¤ì¹­ëœ ë²•ë ¹/í–‰ì •ê·œì¹™ passage
#    - ì˜ˆì‹œ:
#      {
#        "query_text": "ìœ„ìë£Œ ì‚°ì •ì´ ê³¼ì†Œí•˜ì—¬ ë¶€ë‹¹í•˜ë‹¤ê³  ì¸ì •ëœ ì‚¬ë¡€ì— ëŒ€í•œ ë²•ì  íŒë‹¨ì€?",
#        "positive_passages": ["LAW_001706_ì œ751ì¡°_â‘ ", "LAW_001706_ì œ751ì¡°_â‘¡"],
#        "meta": {"type": "prec_to_law_admin", "matched_laws": 1, "matched_admin": 0}
#      }
#
# 2. Fallback: íŒë¡€ ë³¸ë¬¸ ì²­í¬ ì‚¬ìš©
#    - ì°¸ì¡°ì¡°ë¬¸ì´ ì—†ê±°ë‚˜ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ
#    - íŒë¡€ ë³¸ë¬¸ì„ ì²­í¬ë¡œ ë¶„í• í•œ passageë¥¼ ì‚¬ìš©
#    - prec_fallback_passages.jsonlì— ì €ì¥ë¨
#
poetry run lex-dpr gen-data
# ë˜ëŠ” íŒë¡€ ì›ë³¸ JSON ë””ë ‰í† ë¦¬ë¥¼ ì§ì ‘ ì§€ì •:
poetry run lex-dpr gen-data \
  --law data/processed/law_passages.jsonl \
  --admin data/processed/admin_passages.jsonl \
  --prec-json-dir data/precedents \
  --out data/pairs_train.jsonl

# ê²°ê³¼ íŒŒì¼:
#   - data/pairs_train.jsonl
#   - data/pairs_train_valid.jsonl
#   - data/pairs_train_test.jsonl
#   - data/pairs_eval.jsonl (valid ì„¸íŠ¸ ë³µì‚¬ë³¸, í•™ìŠµ/í‰ê°€ì— ì‚¬ìš©)

# ============================================
# ğŸ“Œ ì¶”ê°€ ë°ì´í„° ì¤€ë¹„ (ì„ íƒì‚¬í•­)
# ============================================

# 2-1. (ì„ íƒ) íŒë¡€ í¬ë¡¤ë§ - law.go.krì—ì„œ íŒë¡€ JSON ìˆ˜ì§‘
#    PAGE ë²ˆí˜¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘ í˜ì´ì§€ì™€ ìµœëŒ€ í˜ì´ì§€ ìˆ˜ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#    (íŒë¡€ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì¶”ê°€ë¡œ ìˆ˜ì§‘í•˜ë ¤ëŠ” ê²½ìš°)
poetry run lex-dpr crawl-precedents --max-pages 50
# ë˜ëŠ”
poetry run lex-dpr crawl-precedents --start-page 51 --max-pages 50

# 3. í•™ìŠµ ëª…ë ¹ì–´ ì •ë¦¬
# ============================================
# ğŸ“Œ ëª…ë ¹ì–´ë³„ ìš©ë„ ìš”ì•½:
# 
# 1. train: ì§€ì •ëœ íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ
#    - configs/base.yaml ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ
#    - ëª¨ë“  ê¸°ëŠ¥ì„ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì • ê°€ëŠ¥
#    - ì‹¤ì œ í•™ìŠµ ì‹œ ì‚¬ìš©
#
# 2. smoke-train: ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™” + ë°˜ë³µ íŒŒë¼ë¯¸í„°ë§Œ ì œí•œ
#    - ëª¨ë“  ê¸°ëŠ¥ ìë™ í™œì„±í™” (LR scheduler, gradient clipping, early stopping)
#    - test_run=true, epochs=1ë¡œ ì œí•œí•˜ì—¬ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
#    - íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸ìš©
#
# 3. sweep: ì§€ì •ëœ íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
#    - configs/sweep.yaml ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
#    - WandB Sweepì„ í†µí•œ Bayesian optimization
#    - ì‹¤ì œ ìµœì í™” ì‹œ ì‚¬ìš©
#
# 4. smoke-sweep: ìµœì†Œí•œì˜ ê¸°ëŠ¥ + ìµœì†Œí•œì˜ ë°˜ë³µìœ¼ë¡œ sweep í…ŒìŠ¤íŠ¸
#    - sweep ëª…ë ¹ì–´ì— --smoke-test í”Œë˜ê·¸ ì‚¬ìš©
#    - ë˜ëŠ” configs/smoke_sweep.yaml ì‚¬ìš©
#    - Sweep íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸ìš©
# ============================================

# 3-1. ì •ìƒ í•™ìŠµ (train)
#     - configs/base.yaml ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ
#     - ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •
poetry run lex-dpr train
# ë˜ëŠ” ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ:
poetry run lex-dpr train trainer.epochs=5 trainer.lr=3e-5

# 3-2. ë¹ ë¥¸ SMOKE TEST í•™ìŠµ (smoke-train)
#     - ëª¨ë“  ê¸°ëŠ¥ ìë™ í™œì„±í™”:
#       * Learning Rate Scheduler: Warm-up + Cosine Annealing
#       * Gradient Clipping: í™œì„±í™” (max_norm=1.0)
#       * Early Stopping: í™œì„±í™” (patience=2)
#     - ë°˜ë³µ íŒŒë¼ë¯¸í„°ë§Œ ì œí•œ: test_run=true, epochs=1
#     - íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸ìš©
poetry run lex-dpr smoke-train
# ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ë®ì–´ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (test_run/epochs/ê¸°ëŠ¥ í™œì„±í™”ëŠ” ê³ ì •):
poetry run lex-dpr smoke-train trainer.lr=3e-5

# 3-2. Early Stopping í™œì„±í™”
#     - Validation ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œ
#     - ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì €ì¥
#     configs/base.yamlì—ì„œ ì„¤ì •:
#       trainer:
#         early_stopping:
#           enabled: true
#           metric: "cosine_ndcg@10"  # ëª¨ë‹ˆí„°ë§í•  ë©”íŠ¸ë¦­
#           patience: 3  # ê°œì„ ì´ ì—†ì„ ë•Œ ê¸°ë‹¤ë¦´ í‰ê°€ íšŸìˆ˜
#           mode: "max"  # "max" ë˜ëŠ” "min"
#     ë˜ëŠ” ëª…ë ¹ì¤„ì—ì„œ:
poetry run lex-dpr train trainer.early_stopping.enabled=true trainer.early_stopping.patience=5

# í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬: Warm-up + Cosine Annealing
# - ì „ì²´ í•™ìŠµ stepì˜ 10%ì—ì„œ warmup ìˆ˜í–‰
# - ì´í›„ cosine annealingìœ¼ë¡œ í•™ìŠµë¥  ê°ì†Œ
# - ìë™ìœ¼ë¡œ ì„¤ì •ë˜ë¯€ë¡œ ë³„ë„ ì„¤ì • ë¶ˆí•„ìš”

# 3-3. Gradient Clipping í™œì„±í™”
#     - Gradient explosion ë°©ì§€ë¥¼ ìœ„í•œ gradient clipping
#     configs/base.yamlì—ì„œ ì„¤ì •:
#       trainer:
#         gradient_clip_norm: 1.0  # ìµœëŒ€ ë…¸ë¦„ ê°’ (0.0ì´ë©´ ë¹„í™œì„±í™”)
#     ë˜ëŠ” ëª…ë ¹ì¤„ì—ì„œ:
poetry run lex-dpr train trainer.gradient_clip_norm=1.0

# 4. í•™ìŠµëœ ëª¨ë¸ í‰ê°€
#    MRR@k, NDCG@k, MAP@k, Precision/Recall@k ë“± Retrieval ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

# ê¸°ë³¸ í‰ê°€ (JSON ì¶œë ¥)
poetry run lex-dpr eval
poetry run lex-dpr eval \
  --model checkpoint/lexdpr/bi_encoder \
  --passages data/processed/merged_corpus.jsonl \
  --eval-pairs data/pairs_eval.jsonl \
  --k-values 1 3 5 10 \
  --output eval_results.json

# ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ (ì¿¼ë¦¬ë³„, ì†ŒìŠ¤ë³„, ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„ í¬í•¨)
poetry run lex-dpr eval \
  --model checkpoint/lexdpr/bi_encoder \
  --detailed \
  --report eval_detailed_report.txt \
  --output eval_detailed_results.json

# ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ í‰ê°€ (Sweepìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ë“¤ ë¹„êµ)
poetry run lex-dpr eval \
  --compare-models \
    checkpoint/model1 \
    checkpoint/model2 \
    checkpoint/model3 \
  --compare-output model_comparison_report.txt \
  --output model_comparison.json

# 4-1. ì„ë² ë”© í’ˆì§ˆ ì‹œê°í™”
# ============================================
# í•™ìŠµëœ ëª¨ë¸ì˜ ì„ë² ë”© í’ˆì§ˆì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# 
# ì‹œê°í™” íƒ€ì…:
# - embedding-space: ì„ë² ë”© ê³µê°„ ì‹œê°í™” (t-SNE/UMAP)
# - similarity: Positive vs Negative ìœ ì‚¬ë„ ë¶„í¬
# - heatmap: ì¿¼ë¦¬-íŒ¨ì‹œì§€ ìœ ì‚¬ë„ íˆíŠ¸ë§µ
# - comparison: í•™ìŠµ ì „í›„ ë¹„êµ
# ============================================

# ëª¨ë“  ì‹œê°í™” ìƒì„±
poetry run lex-dpr visualize \
  --model checkpoint/lexdpr/bi_encoder \
  --passages data/merged_corpus.jsonl \
  --eval-pairs data/pairs_eval.jsonl \
  --output visualizations

# íŠ¹ì • ì‹œê°í™”ë§Œ ìƒì„±
poetry run lex-dpr visualize \
  --model checkpoint/lexdpr/bi_encoder \
  --type similarity \
  --output visualizations

# í•™ìŠµ ì „í›„ ë¹„êµ (í•™ìŠµ ì „ ëª¨ë¸ê³¼ ë¹„êµ)
poetry run lex-dpr visualize \
  --model checkpoint/lexdpr/bi_encoder \
  --model-before ko-simcse \
  --type comparison \
  --output visualizations

# UMAP ëŒ€ì‹  t-SNE ì‚¬ìš©
poetry run lex-dpr visualize \
  --model checkpoint/lexdpr/bi_encoder \
  --type space \
  --method tsne \
  --output visualizations

# 4-2. ì„ë² ë”© ìƒì„± ë° ì‚¬ìš©
# ============================================
# í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆì˜(query)ì™€ íŒ¨ì‹œì§€(passage)ì˜ ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# 
# ì‚¬ìš© ë°©ë²•:
# 1. Python API: ì½”ë“œì—ì„œ ì§ì ‘ BiEncoder í´ë˜ìŠ¤ ì‚¬ìš©
# 2. CLI: ëª…ë ¹ì¤„ì—ì„œ ë°°ì¹˜ ì„ë² ë”© ìƒì„±
# ============================================

# ë°©ë²• 1: Python API ì‚¬ìš©
# ------------------------
# íŒ¨í‚¤ì§€ì—ì„œ ì§ì ‘ BiEncoderë¥¼ importí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#
# âš ï¸ ì£¼ì˜: íŒ¨í‚¤ì§€ê°€ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”:
#   python -c "from lex_dpr import BiEncoder, TemplateMode; print('âœ… ì„¤ì¹˜ ì„±ê³µ')"
#
# ì˜ˆì‹œ ì½”ë“œ:
from lex_dpr import BiEncoder, TemplateMode
import numpy as np

# ë°©ë²• 1: ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© (íŒ¨í‚¤ì§€ ë°°í¬ìê°€ ì„¤ì •í•œ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ)
# ì‚¬ìš©ìëŠ” run IDë¥¼ ëª°ë¼ë„ ë©ë‹ˆë‹¤!
encoder = BiEncoder()  # ë˜ëŠ” BiEncoder("default")
# ì²« ì‹¤í–‰ ì‹œ WandBì—ì„œ ìë™ìœ¼ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
# ì´í›„ ì‹¤í–‰ ì‹œì—ëŠ” ìºì‹œëœ ëª¨ë¸ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.

# ë°©ë²• 2: íŠ¹ì • ëª¨ë¸ ê²½ë¡œ ì§€ì •
encoder = BiEncoder(
    "checkpoint/lexdpr/bi_encoder",
    template=TemplateMode.BGE,  # ë˜ëŠ” TemplateMode.NONE
    normalize=True,  # ì„ë² ë”© ì •ê·œí™” (ê¸°ë³¸ê°’: True)
    max_seq_length=512,  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
)

# ì§ˆì˜ ì„ë² ë”© ìƒì„±
queries = [
    "ë²•ë¥  ì§ˆì˜ í…ìŠ¤íŠ¸ 1",
    "ë²•ë¥  ì§ˆì˜ í…ìŠ¤íŠ¸ 2",
]
query_embeddings = encoder.encode_queries(queries, batch_size=64)
print(f"Query embeddings shape: {query_embeddings.shape}")  # (2, embedding_dim)

# íŒ¨ì‹œì§€ ì„ë² ë”© ìƒì„±
passages = [
    "ë²•ë¥  ë¬¸ì„œ íŒ¨ì‹œì§€ 1",
    "ë²•ë¥  ë¬¸ì„œ íŒ¨ì‹œì§€ 2",
]
passage_embeddings = encoder.encode_passages(passages, batch_size=64)
print(f"Passage embeddings shape: {passage_embeddings.shape}")  # (2, embedding_dim)

# ìœ ì‚¬ë„ ê³„ì‚° (cosine similarity)
from sklearn.metrics.pairwise import cosine_similarity
similarities = cosine_similarity(query_embeddings, passage_embeddings)
print(f"Similarity matrix:\n{similarities}")

# ë°©ë²• 2: CLI ì‚¬ìš© (ë°°ì¹˜ ì„ë² ë”© ìƒì„±)
# ------------------------
# JSONL íŒŒì¼ì—ì„œ ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ì§ˆì˜ ì„ë² ë”© ìƒì„±
poetry run lex-dpr embed \
  --model checkpoint/lexdpr/bi_encoder \
  --input data/queries.jsonl \
  --outdir embeddings \
  --prefix queries \
  --type query \
  --batch-size 64 \
  --template bge

# íŒ¨ì‹œì§€ ì„ë² ë”© ìƒì„±
poetry run lex-dpr embed \
  --model checkpoint/lexdpr/bi_encoder \
  --input data/processed/law_passages.jsonl \
  --outdir embeddings \
  --prefix passages \
  --type passage \
  --batch-size 64 \
  --template bge

# CLI ì˜µì…˜ ì„¤ëª…:
#   --model: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (í•„ìˆ˜)
#   --input: ì…ë ¥ JSONL íŒŒì¼ ê²½ë¡œ (í•„ìˆ˜)
#   --outdir: ì„ë² ë”© ì €ì¥ ë””ë ‰í† ë¦¬ (í•„ìˆ˜)
#   --prefix: ì¶œë ¥ íŒŒì¼ ì ‘ë‘ì‚¬ (ì˜ˆ: "queries", "passages") (í•„ìˆ˜)
#   --type: ì„ë² ë”© íƒ€ì… ("query" ë˜ëŠ” "passage") (í•„ìˆ˜)
#   --id-field: JSONLì—ì„œ ID í•„ë“œëª… (ê¸°ë³¸ê°’: "id")
#   --text-field: JSONLì—ì„œ í…ìŠ¤íŠ¸ í•„ë“œëª… (ê¸°ë³¸ê°’: "text")
#   --template: í…œí”Œë¦¿ ëª¨ë“œ ("bge" ë˜ëŠ” "none", ê¸°ë³¸ê°’: "bge")
#   --batch-size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 64)
#   --max-len: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ (0ì´ë©´ ëª¨ë¸ ê¸°ë³¸ê°’ ì‚¬ìš©, ê¸°ë³¸ê°’: 0)
#   --device: ë””ë°”ì´ìŠ¤ ("cuda" ë˜ëŠ” "cpu", ê¸°ë³¸ê°’: ìë™ ê°ì§€)
#   --output-format: ì¶œë ¥ í˜•ì‹ ("npz", "npy", "both", ê¸°ë³¸ê°’: "npz")
#   --limit: ì¸ì½”ë”©í•  í–‰ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©, ê¸°ë³¸ê°’: None)
#   --no-normalize: ì„ë² ë”© ì •ê·œí™” ë¹„í™œì„±í™”
#   --peft-adapter: PEFT ì–´ëŒ‘í„° ê²½ë¡œ (ì¼ë°˜ì ìœ¼ë¡œ ìë™ ê°ì§€)

# ì¶œë ¥ íŒŒì¼ í˜•ì‹:
# - NPZ í˜•ì‹ (ê¸°ë³¸): {prefix}.npz (idsì™€ embeddings í¬í•¨)
# - NPY í˜•ì‹: {prefix}_ids.npy, {prefix}_embeds.npy
# - both: ë‘ í˜•ì‹ ëª¨ë‘ ì €ì¥

# ì„ë² ë”© ë¡œë“œ ì˜ˆì‹œ:
import numpy as np

# NPZ í˜•ì‹ ë¡œë“œ
data = np.load("embeddings/queries.npz")
ids = data["ids"]
embeddings = data["embeddings"]

# NPY í˜•ì‹ ë¡œë“œ
ids = np.load("embeddings/queries_ids.npy", allow_pickle=True)
embeddings = np.load("embeddings/queries_embeds.npy")

# ì…ë ¥ JSONL í˜•ì‹ ì˜ˆì‹œ:
# {"id": "query_1", "text": "ë²•ë¥  ì§ˆì˜ í…ìŠ¤íŠ¸"}
# {"id": "query_2", "text": "ë‹¤ë¥¸ ì§ˆì˜ í…ìŠ¤íŠ¸"}

# í•™ìŠµëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (WandBì—ì„œ)
# ------------------------
# WandBì— ì—…ë¡œë“œëœ í•™ìŠµëœ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ê¸°ë³¸ ì‚¬ìš© (ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ)
poetry run lex-dpr download-model

# íŠ¹ì • Sweep ID ì§€ì •
poetry run lex-dpr download-model --sweep-id <sweep-id>

# ë©”íŠ¸ë¦­ ë° ì¶œë ¥ ê²½ë¡œ ì§€ì •
poetry run lex-dpr download-model \
  --metric eval/ndcg@10 \
  --output-dir checkpoint/my_model \
  --project lexdpr \
  --entity zae-park

# âš ï¸ ì¤‘ìš”: í•™ìŠµ ì„¤ì • ìë™ ì ìš©
# ------------------------
# WandBì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì€ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ max_lenì´ ìë™ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.
# 
# ë‹¤ìš´ë¡œë“œ ì‹œ:
#   - runì˜ configì—ì„œ max_len ì •ë³´ë¥¼ ì½ì–´ì„œ training_config.jsonì— ì €ì¥
#   - BiEncoderê°€ ëª¨ë¸ì„ ë¡œë“œí•  ë•Œ training_config.jsonì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ max_seq_length ì ìš©
#
# ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •í•˜ë ¤ë©´:
encoder = BiEncoder(
    "checkpoint/lexdpr/bi_encoder",
    max_seq_length=128,  # ëª…ì‹œì ìœ¼ë¡œ ì§€ì • (training_config.jsonì´ ì—†ê±°ë‚˜ ë®ì–´ì“°ë ¤ëŠ” ê²½ìš°)
    template=TemplateMode.BGE,
)

# ì„ë² ë”© ì°¨ì› í™•ì¸:
# ì§ˆì˜ì™€ íŒ¨ì‹œì§€ì˜ ì„ë² ë”© ì°¨ì›ì€ í•­ìƒ ë™ì¼í•©ë‹ˆë‹¤ (ê°™ì€ ëª¨ë¸ ì‚¬ìš©).
embedding_dim = encoder.get_embedding_dimension()
print(f"ì„ë² ë”© ì°¨ì›: {embedding_dim}")  # ì˜ˆ: 768 (ko-simcseì˜ ê²½ìš°)

# ì‹¤ì œ í™•ì¸:
query_emb = encoder.encode_queries(["ì§ˆì˜"])
passage_emb = encoder.encode_passages(["íŒ¨ì‹œì§€"])
print(f"Query shape: {query_emb.shape}")    # (1, 768)
print(f"Passage shape: {passage_emb.shape}")  # (1, 768) - ì°¨ì›ì´ ë™ì¼í•¨

# ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì—ì„œ í•™ìŠµ ì„¤ì • í™•ì¸:
# ------------------------
# ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì˜ í˜„ì¬ max_seq_length í™•ì¸
current_max_len = encoder.get_max_seq_length()
print(f"í˜„ì¬ ëª¨ë¸ max_seq_length: {current_max_len}")

# PEFT ì–´ëŒ‘í„° ì„¤ì • í™•ì¸ (PEFT ëª¨ë¸ì¸ ê²½ìš°)
training_config = encoder.get_training_config()
if training_config:
    print(f"Base ëª¨ë¸: {training_config.get('base_model_name_or_path')}")
    print(f"LoRA r: {training_config.get('r')}")
    print(f"LoRA alpha: {training_config.get('lora_alpha')}")
    print(f"Target modules: {training_config.get('target_modules')}")

# âš ï¸ ì£¼ì˜: WandBì— ì €ì¥ë˜ëŠ” ëª¨ë¸ì€ PEFT ì–´ëŒ‘í„°ë§Œ ì €ì¥ë©ë‹ˆë‹¤
# - Base ëª¨ë¸ì€ HuggingFaceì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤
# - ì–´ëŒ‘í„° í¬ê¸°ëŠ” ë§¤ìš° ì‘ìŠµë‹ˆë‹¤ (ìˆ˜ MB ~ ìˆ˜ì‹­ MB)
# - íŒ¨í‚¤ì§€ì— í¬í•¨ ê°€ëŠ¥í•œ í¬ê¸°ì´ì§€ë§Œ, base ëª¨ë¸ì€ ë³„ë„ ë‹¤ìš´ë¡œë“œ í•„ìš”

# ê³ ê¸‰ ì‚¬ìš©ë²•:
# ------------------------
# Queryì™€ Passageì— ì„œë¡œ ë‹¤ë¥¸ ìµœëŒ€ ê¸¸ì´ ì„¤ì •
from lex_dpr import BiEncoder, TemplateMode

encoder = BiEncoder(
    "checkpoint/lexdpr/bi_encoder",
    template=TemplateMode.BGE,
    normalize=True,
    query_max_seq_length=128,  # ì§ˆì˜ëŠ” ì§§ê²Œ
    passage_max_seq_length=512,  # íŒ¨ì‹œì§€ëŠ” ê¸¸ê²Œ
)

# PEFT ì–´ëŒ‘í„° ì‚¬ìš©
encoder = BiEncoder(
    "base_model_name",
    peft_adapter_path="checkpoint/lexdpr/bi_encoder",  # PEFT ì–´ëŒ‘í„° ê²½ë¡œ
)

# ì„ë² ë”© ì°¨ì› í™•ì¸
embedding_dim = encoder.get_embedding_dimension()
print(f"ì„ë² ë”© ì°¨ì›: {embedding_dim}")  # ì§ˆì˜ì™€ íŒ¨ì‹œì§€ ëª¨ë‘ ë™ì¼í•œ ì°¨ì›

# âš ï¸ ì¤‘ìš”: í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì‹œí€€ìŠ¤ ê¸¸ì´ í™•ì¸
# í•™ìŠµ ì‹œ max_len=128ë¡œ í•™ìŠµí–ˆë‹¤ë©´ (configs/model.yaml í™•ì¸):
encoder = BiEncoder(
    "checkpoint/lexdpr/bi_encoder",
    max_seq_length=128,  # í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ ì„¤ì •í•´ì•¼ í•¨
    template=TemplateMode.BGE,  # í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ
)

# 5. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (WandB Sweep)
# ============================================
# ğŸ“Œ Sweep ëª…ë ¹ì–´ ì •ë¦¬:
#
# 1. sweep (ì‹¤ì œ): configs/sweep.yaml ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
#    - Bayesian optimizationìœ¼ë¡œ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰
#    - ì—¬ëŸ¬ ë‚ ì§œì— ë‚˜ëˆ ì„œ ì‹¤í–‰ ê°€ëŠ¥
#
# 2. sweep (smoke-test): ìµœì†Œí•œì˜ ê¸°ëŠ¥ + ìµœì†Œí•œì˜ ë°˜ë³µìœ¼ë¡œ sweep í…ŒìŠ¤íŠ¸
#    - --smoke-test í”Œë˜ê·¸ ì‚¬ìš© ë˜ëŠ” configs/smoke_sweep.yaml ì‚¬ìš©
#    - Sweep íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸ìš©
# ============================================

# 5-1. ì‹¤ì œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ (sweep)
#     - configs/sweep.yaml ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
#     - Bayesian optimizationìœ¼ë¡œ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰
#     - ì—¬ëŸ¬ ë‚ ì§œì— ë‚˜ëˆ ì„œ ì‹¤í–‰ ê°€ëŠ¥
poetry run lex-dpr sweep --config configs/sweep.yaml --no-smoke-test

# 5-2. Sweep íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (smoke-sweep)
#     - ìµœì†Œí•œì˜ ê¸°ëŠ¥, ìµœì†Œí•œì˜ ë°˜ë³µ íŒŒë¼ë¯¸í„°ë¡œ sweep í…ŒìŠ¤íŠ¸
#     - Sweep íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸ìš©
poetry run lex-dpr sweep --smoke-test
# ë˜ëŠ” ì„¤ì • íŒŒì¼ ì§ì ‘ ì§€ì •:
poetry run lex-dpr sweep --config configs/smoke_sweep.yaml --smoke-test

# 5-3. ìŠ¤ìœ• ì„¤ì • íŒŒì¼ ìƒì„± (í…œí”Œë¦¿)
poetry run lex-dpr sweep init --output configs/my_sweep.yaml
# SMOKE TEST ëª¨ë“œìš© í…œí”Œë¦¿ ìƒì„±:
poetry run lex-dpr sweep init --output configs/smoke_sweep.yaml --smoke-test

# 5-4. ì„¤ì • íŒŒì¼ í¸ì§‘ (íƒìƒ‰í•  íŒŒë¼ë¯¸í„° ë²”ìœ„ ì„¤ì •)
# vim configs/my_sweep.yaml
#
# ì˜ˆì‹œ ì„¤ì • (configs/my_sweep.yaml):
# ---
# method: bayes  # grid, random, bayes ì¤‘ ì„ íƒ
# metric:
#   name: eval/ndcg@10
#   goal: maximize
# parameters:
#   trainer.lr:
#     distribution: log_uniform_values
#     values: [1e-6, 1e-5, 1e-4, 1e-3]
#   trainer.temperature:
#     distribution: uniform
#     min: 0.01
#     max: 0.2
# fixed:
#   trainer.epochs: 3
#   data.pairs: data/pairs_train.jsonl
#   data.passages: data/merged_corpus.jsonl
# # ì‹œê°„ ê¸°ë°˜ ì œì–´ (ì„ íƒì‚¬í•­)
# time_window: "1-8"  # 1ì‹œ~8ì‹œì—ë§Œ ì‹¤í–‰ (KST ê¸°ì¤€)
# timezone: "Asia/Seoul"
# # Early termination ì„¤ì • (ì„ íƒì‚¬í•­, ë² ì´ì§€ì•ˆ íƒìƒ‰ ìˆ˜ë ´ ì‹œ ìë™ ì¢…ë£Œ)
# early_terminate:
#   type: hyperband
#   min_iter: 3
#   max_iter: 27
#   s: 2

# 5-3. ìŠ¤ìœ• ì‹œì‘ (WandBì— ìŠ¤ìœ• ìƒì„±)
# ë°©ë²• 1: ìŠ¤ìœ• ìƒì„± + ì—ì´ì „íŠ¸ ìë™ ì‹¤í–‰ (ê¸°ë³¸ ë™ì‘)
poetry run lex-dpr sweep
# ë˜ëŠ”
poetry run lex-dpr sweep start --config configs/my_sweep.yaml

# ë°©ë²• 2: ìŠ¤ìœ•ë§Œ ìƒì„±í•˜ê³  ì—ì´ì „íŠ¸ëŠ” ë‚˜ì¤‘ì— ì‹¤í–‰
poetry run lex-dpr sweep --no-run-agent
# ë˜ëŠ”
poetry run lex-dpr sweep start --config configs/my_sweep.yaml --no-run-agent

# SMOKE TEST ëª¨ë“œë¡œ ì‹¤í–‰ (test_run=true, epochs=1 ìë™ ì ìš©):
poetry run lex-dpr sweep start --config configs/my_sweep.yaml --smoke-test

# 5-6. ì—ì´ì „íŠ¸ ì‹¤í–‰ (ì—¬ëŸ¬ ë‚ ì§œ/ë¨¸ì‹ ì—ì„œ ë‚˜ëˆ ì„œ ì‹¤í–‰ ê°€ëŠ¥)
# ì„¤ì • íŒŒì¼ì—ì„œ ìŠ¤ìœ• ID ìë™ ì½ê¸°:
poetry run lex-dpr sweep agent --config configs/my_sweep.yaml

# ìŠ¤ìœ• ID ì§ì ‘ ì§€ì •:
poetry run lex-dpr sweep agent <sweep-id>

# íŠ¹ì • íšŸìˆ˜ë§Œ ì‹¤í–‰ (ì˜ˆ: ì˜¤ëŠ˜ì€ 5ê°œë§Œ):
poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --count 5

# ì‹œê°„ ê¸°ë°˜ ì œì–´ (íŠ¹ì • ì‹œê°„ëŒ€ì—ë§Œ ì‹¤í–‰):
# CLIì—ì„œ ì§ì ‘ ì§€ì •:
poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --time-window "1-8" --count 10
# ë˜ëŠ” ì„¤ì • íŒŒì¼ì˜ time_window ì‚¬ìš© (ìë™ ì ìš©)

# ì—¬ëŸ¬ ë‚ ì§œì— ë‚˜ëˆ ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•:
# ì²« ë‚ : poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --count 10 --time-window "1-8"
# ë‘˜ì§¸ ë‚ : poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --count 10 --time-window "1-8"
# ì…‹ì§¸ ë‚ : poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --count 10 --time-window "1-8"
# (ê°™ì€ ìŠ¤ìœ•ì— ê³„ì† ì°¸ì—¬í•˜ì—¬ íƒìƒ‰ ì§„í–‰)

# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ë° ë¡œê·¸ ì €ì¥ (nohup ì‚¬ìš©)
# ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” sweep agentë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•˜ê³  ë¡œê·¸ë¥¼ ì €ì¥:
nohup poetry run lex-dpr sweep agent --config configs/sweep.yaml --count 10 \
  > logs/sweep_agent_$(date +%Y%m%d_%H%M%S).log 2>&1 &

# ë˜ëŠ” ë” ê°„ë‹¨í•˜ê²Œ:
nohup poetry run lex-dpr sweep agent --config configs/sweep.yaml \
  > logs/sweep_agent.log 2>&1 &

# ë¡œê·¸ í™•ì¸:
tail -f logs/sweep_agent.log
# ë˜ëŠ”
less logs/sweep_agent.log

# ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸:
ps aux | grep "sweep agent"

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ (PID í™•ì¸ í›„):
kill <PID>

# WandB ëŒ€ì‹œë³´ë“œì—ì„œ ì§„í–‰ ìƒí™© í™•ì¸:
# https://wandb.ai/<entity>/<project>/sweeps/<sweep-id>

# ìŠ¤ìœ• ì¢…ë£Œ ì¡°ê±´:
# - ê¸°ë³¸ì ìœ¼ë¡œ ë¬´í•œì • ì‹¤í–‰ë¨ (ëª¨ë“  íŒŒë¼ë¯¸í„° ì¡°í•© íƒìƒ‰)
# - --count ì˜µì…˜ìœ¼ë¡œ ì‹¤í–‰ íšŸìˆ˜ ì œí•œ ê°€ëŠ¥
# - WandB ëŒ€ì‹œë³´ë“œì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì¤‘ë‹¨ ê°€ëŠ¥
# - ìŠ¤ìœ• ì„¤ì •ì—ì„œ early_terminate ì„¤ì • ê°€ëŠ¥ (ë² ì´ì§€ì•ˆ íƒìƒ‰ ì‹œ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ìœ¼ë©´ ìë™ ì¢…ë£Œ)
# - ì‹œê°„ ê¸°ë°˜ ì œì–´: time_window ì„¤ì • ì‹œ ì§€ì •ëœ ì‹œê°„ ë²”ìœ„ ë°–ì—ì„œëŠ” ìë™ ëŒ€ê¸°
```

---

## ğŸ”§ WandB Sweep í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìƒì„¸ ê°€ì´ë“œ

LexDPRì€ WandB Sweepì„ í†µí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹ì„ ì§€ì›í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ë‚ ì§œì— ë‚˜ëˆ ì„œ ì‹¤í–‰í•˜ê±°ë‚˜, íŠ¹ì • ì‹œê°„ëŒ€ì—ë§Œ ì‹¤í–‰í•˜ëŠ” ë“± ìœ ì—°í•œ ìŠ¤ìœ• ê´€ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

- **ë‹¤ì–‘í•œ íƒìƒ‰ ë°©ë²•**: Grid Search, Random Search, Bayesian Optimization
- **ì—¬ëŸ¬ ë‚ ì§œ/ë¨¸ì‹ ì—ì„œ ì‹¤í–‰**: ê°™ì€ ìŠ¤ìœ•ì— ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ ì°¸ì—¬í•˜ì—¬ ë³‘ë ¬ íƒìƒ‰
- **ì‹œê°„ ê¸°ë°˜ ì œì–´**: íŠ¹ì • ì‹œê°„ëŒ€ì—ë§Œ ì‹¤í–‰í•˜ë„ë¡ ì„¤ì • ê°€ëŠ¥ (ì˜ˆ: ì•¼ê°„ ì‹œê°„ëŒ€)
- **Early Termination**: ë² ì´ì§€ì•ˆ íƒìƒ‰ ì‹œ ì„±ëŠ¥ ê°œì„ ì´ ì—†ìœ¼ë©´ ìë™ ì¢…ë£Œ
- **SMOKE TEST ëª¨ë“œ**: ë¹ ë¥¸ ê²€ì¦ì„ ìœ„í•œ ì¶•ì†Œ ëª¨ë“œ ì§€ì›

### ìŠ¤ìœ• ì„¤ì • íŒŒì¼ ì˜ˆì‹œ

```yaml
# configs/my_sweep.yaml
method: bayes  # grid, random, bayes ì¤‘ ì„ íƒ

metric:
  name: eval/ndcg@10
  goal: maximize

parameters:
  trainer.lr:
    distribution: log_uniform_values
    values: [1e-6, 1e-5, 1e-4, 1e-3]
  
  trainer.temperature:
    distribution: uniform
    min: 0.01
    max: 0.2
  
  trainer.gradient_accumulation_steps:
    values: [4, 8, 16]

fixed:
  trainer.epochs: 3
  data.pairs: data/pairs_train.jsonl
  data.passages: data/merged_corpus.jsonl

# ì‹œê°„ ê¸°ë°˜ ì œì–´ (ì„ íƒì‚¬í•­)
time_window: "1-8"  # 1ì‹œ~8ì‹œì—ë§Œ ì‹¤í–‰ (KST ê¸°ì¤€)
timezone: "Asia/Seoul"

# Early Termination ì„¤ì • (ì„ íƒì‚¬í•­)
early_terminate:
  type: hyperband
  min_iter: 3
  max_iter: 27
  s: 2
```

### ì‹œê°„ ê¸°ë°˜ ì œì–´ ì‚¬ìš©ë²•

ìŠ¤ìœ• ì—ì´ì „íŠ¸ë¥¼ íŠ¹ì • ì‹œê°„ëŒ€ì—ë§Œ ì‹¤í–‰í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” GPU ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, íŠ¹ì • ì‹œê°„ëŒ€ì—ë§Œ í•™ìŠµì„ ì§„í–‰í•˜ê³  ì‹¶ì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

```bash
# CLIì—ì„œ ì§ì ‘ ì§€ì •
poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --time-window "1-8" --count 10

# ì„¤ì • íŒŒì¼ì— time_windowê°€ ìˆìœ¼ë©´ ìë™ ì ìš©
poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --count 10
```

ì‹œê°„ ë²”ìœ„ ë°–ì—ì„œ ì‹¤í–‰í•˜ë©´, ì—ì´ì „íŠ¸ëŠ” ë‹¤ìŒ ì‹œì‘ ì‹œê°„ê¹Œì§€ ìë™ìœ¼ë¡œ ëŒ€ê¸°í•©ë‹ˆë‹¤.

### ì—¬ëŸ¬ ë‚ ì§œì— ë‚˜ëˆ ì„œ ì‹¤í–‰

í° ìŠ¤ìœ•ì„ ì—¬ëŸ¬ ë‚ ì— ê±¸ì³ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# ì²« ë‚ : 10ê°œ ì‹¤í–‰
poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --count 10 --time-window "1-8"

# ë‘˜ì§¸ ë‚ : ë˜ 10ê°œ ì‹¤í–‰ (ê°™ì€ ìŠ¤ìœ•ì— ê³„ì† ì°¸ì—¬)
poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --count 10 --time-window "1-8"

# ì…‹ì§¸ ë‚ : ë§ˆì§€ë§‰ 10ê°œ ì‹¤í–‰
poetry run lex-dpr sweep agent --config configs/my_sweep.yaml --count 10 --time-window "1-8"
```

ê° ë‚ ì§œë§ˆë‹¤ ì‹¤í–‰í•œ ê²°ê³¼ëŠ” ëª¨ë‘ ê°™ì€ ìŠ¤ìœ•ì— ëˆ„ì ë˜ì–´ WandB ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Early Termination ì„¤ì •

ë² ì´ì§€ì•ˆ íƒìƒ‰(Bayesian Optimization)ì„ ì‚¬ìš©í•  ë•Œ, ì„±ëŠ¥ ê°œì„ ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìŠ¤ìœ•ì„ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```yaml
early_terminate:
  type: hyperband
  min_iter: 3      # ìµœì†Œ ë°˜ë³µ íšŸìˆ˜
  max_iter: 27     # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
  s: 2             # Successive Halving íŒŒë¼ë¯¸í„°
```

ì´ ì„¤ì •ì€ WandBì˜ Hyperband ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì´ ë‚®ì€ ì‹¤í–‰ì„ ì¡°ê¸°ì— ì¢…ë£Œí•˜ê³ , ìœ ë§í•œ ì‹¤í–‰ì— ë” ë§ì€ ë¦¬ì†ŒìŠ¤ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.

### SMOKE TEST ëª¨ë“œ

ìŠ¤ìœ• ì„¤ì •ì´ ì˜¬ë°”ë¥¸ì§€ ë¹ ë¥´ê²Œ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ SMOKE TEST ëª¨ë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# SMOKE TEST ëª¨ë“œìš© ì„¤ì • íŒŒì¼ ìƒì„±
poetry run lex-dpr sweep init --output configs/smoke_sweep.yaml --smoke-test

# SMOKE TEST ëª¨ë“œë¡œ ìŠ¤ìœ• ì‹¤í–‰
poetry run lex-dpr sweep start --config configs/smoke_sweep.yaml --smoke-test
```

SMOKE TEST ëª¨ë“œì—ì„œëŠ” `test_run=true`, `epochs=1`ì´ ìë™ìœ¼ë¡œ ì ìš©ë˜ì–´ ë¹ ë¥´ê²Œ ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸš€ ì‚¬ìš© ì˜ˆì‹œ (DEPRECATED)

```bash
# 1. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 2. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ëª¨ë¸ ê°€ì¤‘ì¹˜ ìë™ ë‹¤ìš´ë¡œë“œ)
bash run_demo_real.sh
```

ë˜ëŠ” ìˆ˜ë™ ì‹¤í–‰:

```bash
# ì „ì²˜ë¦¬
python scripts/preprocess_acts.py --input data/statutes --output data/processed/corpus.jsonl
python scripts/preprocess_acts.py --input data/no_action_letters --output data/processed/tmp.jsonl
cat data/processed/tmp.jsonl >> data/processed/corpus.jsonl && rm data/processed/tmp.jsonl

# ì„ë² ë”© ìƒì„±
python scripts/encode_passages.py --input data/processed/corpus.jsonl --outdir checkpoint
python scripts/encode_queries.py --queries data/queries/queries.jsonl --outdir checkpoint

# ì¸ë±ìŠ¤ ë¹Œë“œ ë° í‰ê°€
python scripts/build_index.py --input checkpoint --output index --factory Flat --metric dot
python scripts/evaluate.py --index_dir index --queries data/queries/queries.jsonl --top_k 10
```

---

## ğŸ“„ Model Ablation Study

### ğŸ§© í•œêµ­ì–´ ì „ìš© ë¦¬íŠ¸ë¦¬ë²„ í›„ë³´ (Bi-Encoder)

| í•­ëª©               | **KoSimCSE-roberta-multitask**                               | **KLUE-RoBERTa-base-bi**                               | **KoE5-small**                                             |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------ | ---------------------------------------------------------- |
| **ëª¨ë¸ íƒ€ì…**      | Sentence-BERTí˜• Bi-Encoder                                   | RoBERTa ê¸°ë°˜ Dual Encoder (LexDPRì— ì í•©)              | E5 ê³„ì—´ Encoder (í•œêµ­ì–´ ì „ìš©)                              |
| **íŒŒë¼ë¯¸í„° ìˆ˜**    | â‰ˆ110 M                                                       | â‰ˆ125 M                                                 | â‰ˆ80 M                                                      |
| **í•™ìŠµ ë°©ì‹**      | SimCSE + Multitask (STS, NLI)                                | KLUE íƒœìŠ¤í¬ ê¸°ë°˜ pretrain + contrastive fine-tune ê°€ëŠ¥ | Instruction-style (E5 objective: â€œquery: â€¦â€, â€œpassage: â€¦â€) |
| **ì–¸ì–´ ë²”ìœ„**      | í•œêµ­ì–´ only                                                  | í•œêµ­ì–´ only                                            | í•œêµ­ì–´ only (OpenKoE5)                                     |
| **ì„ë² ë”© í’ˆì§ˆ**    | ì¼ìƒ ë¬¸ì¥, QA, ì§§ì€ ì§ˆì˜ì— ê°•í•¨                              | ë¬¸ì¥ ê¸¸ì´ ì¤‘ê°„~ê¸´ ë²•ë ¹ ë¬¸ì²´ì— ì•ˆì •ì                    | E5 objectiveë¡œ ë¬¸ë§¥ë§¤ì¹­ ì„±ëŠ¥ ìš°ìˆ˜                          |
| **ì¥ì **           | â€¢ ê²½ëŸ‰Â·ë¹ ë¦„<br>â€¢ GPU ë©”ëª¨ë¦¬â†“                                 | â€¢ KLUE í‘œì¤€ ë¬¸ì²´ ì í•©<br>â€¢ íŒŒì¸íŠœë‹ ìš©ì´               | â€¢ ìµœì‹  E5 í”„ë ˆì„ì›Œí¬ êµ¬ì¡°<br>â€¢ cosine ì •ê·œí™” ì•ˆì •          |
| **ì•½ì **           | â€¢ ì „ë¬¸ ë²•ë ¹ ë„ë©”ì¸ ì•½í•¨                                      | â€¢ Pretrained ëª¨ë¸ ê³µê°œ ì ìŒ                            | â€¢ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ê³µê°œ ì²´í¬í¬ì¸íŠ¸                          |
| **ì í•© ì‹œë‚˜ë¦¬ì˜¤**  | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…, ì €ìì› í™˜ê²½                                 | ì¤‘ëŒ€í˜• ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì¶• (LexDPR êµ¬ì¡°ì— ìì—° ì í•©)         | ë„ë©”ì¸ í™•ì¥ ì‹¤í—˜, E5í˜•ì‹ íŒŒì´í”„ë¼ì¸ ì¼ì¹˜                   |
| **LexDPR ì ìš© ì‹œ** | ê·¸ëŒ€ë¡œ `--model BM-K/KoSimCSE-roberta-multitask`ë¡œ í•™ìŠµ ê°€ëŠ¥ | KLUE-RoBERTa-bië¡œ í•™ìŠµ ì‹œ ì¡°ë¬¸/í•­ ë‹¨ìœ„ ì•ˆì •            | `KoE5-small`ì€ E5 prefix(`query:`, `passage:`) ìœ ì§€ í•„ìš”   |


### ğŸ§© í•œêµ­ì–´ ì „ìš© ë¦¬ë­ì»¤ í›„ë³´ (Cross-Encoder)

| í•­ëª©               | **KLUE-RoBERTa-large (Cross-Encoder)**                             | **KR-ELECTRA-discriminator**                          |
| ------------------ | ------------------------------------------------------------------ | ----------------------------------------------------- |
| **ëª¨ë¸ íƒ€ì…**      | Transformer Cross-Encoder                                          | ELECTRA ê¸°ë°˜ Cross-Encoder                            |
| **íŒŒë¼ë¯¸í„° ìˆ˜**    | â‰ˆ355 M                                                             | â‰ˆ110 M                                                |
| **í•™ìŠµ ë°©ì‹**      | (q,p) ìŒ ì…ë ¥ â†’ relevance classification                           | (q,p) ìŒ ì…ë ¥ â†’ relevance classification              |
| **ì–¸ì–´ ë²”ìœ„**      | í•œêµ­ì–´ only                                                        | í•œêµ­ì–´ only                                           |
| **íŠ¹ì§•**           | RoBERTa ê¸°ë°˜ ë¬¸ë§¥ ì´í•´ ê°•ë ¥, ê¸´ ë¬¸ì¥ì—ë„ ì•ˆì •                      | ì—°ì‚° ê°€ë³ê³  í•™ìŠµ ì†ë„ ë¹ ë¦„                            |
| **ì¥ì **           | â€¢ ë†’ì€ ì •ë°€ë„(Top-10 rerank ì„±ëŠ¥) <br>â€¢ ë¬¸ì¥ ê¸¸ì´ ê¸´ ë²•ë ¹ì—ë„ ì í•© | â€¢ ê²½ëŸ‰, ë¹ ë¥¸ ì¬ë­í¬ â€¢ GPU ìì› ì ˆì•½                   |
| **ì•½ì **           | â€¢ ì§€ì—°ì‹œê°„Â·ë©”ëª¨ë¦¬â†‘                                                 | â€¢ ì„¸ë°€í•œ ë…¼ë¦¬ ê´€ê³„ íŒŒì•… í•œê³„                          |
| **ì í•© ì‹œë‚˜ë¦¬ì˜¤**  | ì˜¤í”„ë¼ì¸ ì¸ë±ìŠ¤ ì¬ë­í¬, ì¤‘ìš” ì§ˆì˜ ì •ë°€ í‰ê°€                        | ì‹¤ì‹œê°„ QA, ì €ìì› í™˜ê²½                                |
| **LexDPR ì ìš© ì‹œ** | `bge-reranker-large` ëŒ€ì²´ë¡œ ì‚¬ìš© ê°€ëŠ¥ (ì…ë ¥: [CLS] q [SEP] p)      | ì†Œê·œëª¨ ì‹¤ì‹œê°„ ì¬ë­í¬ê¸° or lightweight rerankerë¡œ ì í•© |


### ğŸ” ì¡°í•©

| ëª©ì                                | ë¦¬íŠ¸ë¦¬ë²„            | ë¦¬ë­ì»¤                 | ì½”ë©˜íŠ¸                                             |
| ---------------------------------- | ------------------- | ---------------------- | -------------------------------------------------- |
| **ì •ë°€ë„ ì¤‘ì‹¬ (ë²•ë ¹ ê²€ìƒ‰ í’ˆì§ˆ â†‘)** | **KLUE-RoBERTa-bi** | **KLUE-RoBERTa-large** | LexDPRì˜ ê¸°ë³¸ DPR êµ¬ì¡°ì™€ ì™„ë²½ í˜¸í™˜, ë²•ë ¹ ë¬¸ì²´ ì•ˆì • |
| **ê²½ëŸ‰Â·ë¹ ë¥¸ ê²€ìƒ‰**                 | **KoSimCSE**        | **KR-ELECTRA**         | ì‹¤ì‹œê°„ ì§ˆì˜ ì‘ë‹µìš©, ë¹ ë¥¸ inference                 |
| **í™•ì¥í˜•(Instruction ê¸°ë°˜)**       | **KoE5-small**      | **KLUE-RoBERTa-large** | E5 í¬ë§· ìœ ì§€ë¡œ multilingual E5-mistral ì „í™˜ ìš©ì´   |


**! 2ë²ˆ (KoSimCSE+KR-ELECTRA)** ì´í›„ **1ë²ˆ (KLUE-RoBERTa-bi+KLUE-RoBERTa-large)**


---

## ğŸ“„ ì¸ìš© ì •ë³´

```
@misc{lexdpr2025,
  author = {ë°•ì„±ì¬},
  title  = {LexDPR: êµ¬ì¡°í™”ëœ ë²•ë ¹ ë¬¸ì„œë¥¼ ìœ„í•œ Dense Passage Retrieval ëª¨ë¸},
  year   = {2025},
  url    = {https://github.com/zae-park/LexDPR}
}
```

---

## ğŸ§¾ ë¼ì´ì„ ìŠ¤

MIT License  
ê³µê³µë°ì´í„°(ì˜ˆ: ë¹„ì¡°ì¹˜ì˜ê²¬ì„œ, ë²•ë ¹ DB)ëŠ” ê° ì¶œì²˜ì˜ ì˜¤í”ˆë¼ì´ì„ ìŠ¤ ì •ì±…ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- **[Git LFS ì‚¬ìš© ê°€ì´ë“œ](docs/GIT_LFS_GUIDE.md)**: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì™€ ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ Git LFSë¡œ ê´€ë¦¬í•˜ëŠ” ë°©ë²•, org-mirrorì™€ origin ë™ê¸°í™” ì‹œ ì£¼ì˜ì‚¬í•­


###
- https://www.law.go.kr/DRF/lawSearch.do?OC=hanwhasbank01&target=prec&type=HTML&&query=
- https://www.law.go.kr/DRF/lawSearch.do?query=*&target=fsc&OC=hanwhasbank01&search=2&display=20&nw=1&page=2&refAdr=law.go.kr&type=HTML&popYn=N

### 
