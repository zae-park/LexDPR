# BGE-m3-ko OOM 해결 가이드

## 문제 상황

BGE-m3-ko 모델을 사용할 때 대부분의 하이퍼파라미터 조합에서 OOM이 발생하여 정확한 평가가 어려움.

## BGE-m3-ko 모델 정보

- **파라미터 수**: ~560M
- **모델 가중치 크기**: ~1.2GB
- **예상 메모리 사용량** (배치 256, max_len 512):
  - 기본: ~100GB
  - AMP 사용: ~88GB
  - AMP + Gradient Checkpointing: ~78GB

## 해결 방안

### 1. 모델 후보 확장 (완료 ✅)

Sweep에 더 많은 모델을 추가했습니다:

```yaml
model.bi_model:
  values: [
    ko-simcse,  # ~110M, 한국어 전용, 작은 메모리 (권장)
    bge-m3-ko,  # ~560M, 한국어 최적화, 큰 메모리 (OOM 주의)
    multilingual-minilm,  # ~117M, 다국어, 경량
    multilingual-e5-small  # ~118M, 다국어, E5 시리즈
  ]
```

### 2. BGE-m3-ko 사용 시 권장 설정

BGE-m3-ko를 사용할 때는 다음 설정을 권장합니다:

#### A. 배치 크기 제한
```yaml
# bge-m3-ko 사용 시 배치 크기를 작게 설정
data.batches.bi:
  values: [32, 64, 128]  # 256 제거
```

#### B. 시퀀스 길이 제한
```yaml
# bge-m3-ko 사용 시 시퀀스 길이를 작게 설정
model.max_len:
  values: [256, 384]  # 512 제거 또는 256만 사용
```

#### C. 메모리 최적화 필수
```yaml
# 이미 설정됨
trainer.gradient_checkpointing: true  # 필수
trainer.use_amp: true  # 필수
```

### 3. 조건부 설정 (수동 적용)

WandB sweep에서는 조건부 설정이 복잡하므로, 다음과 같이 수동으로 적용할 수 있습니다:

#### 옵션 1: 별도 Sweep 생성
BGE-m3-ko 전용 sweep을 별도로 생성하여 작은 배치 크기와 시퀀스 길이만 사용:

```yaml
# bge-m3-ko 전용 설정
model.bi_model:
  values: [bge-m3-ko]

data.batches.bi:
  values: [32, 64]  # 작은 배치만

model.max_len:
  values: [256, 384]  # 작은 시퀀스만
```

#### 옵션 2: Sweep 실행 후 필터링
WandB 대시보드에서 모델별로 필터링하여 결과 분석:
- `model.bi_model == "bge-m3-ko"` 필터 적용
- 성공한 run만 분석

### 4. 대안 모델 사용

#### ko-simcse (권장)
- **장점**: 
  - 작은 메모리 사용량 (~5-10GB)
  - 한국어 전용으로 성능 우수
  - 빠른 학습 속도
- **단점**: 
  - max_len 128로 제한됨
  - 다국어 미지원

#### multilingual-minilm
- **장점**: 
  - 작은 메모리 사용량 (~10-15GB)
  - 다국어 지원
  - 경량 모델
- **단점**: 
  - 한국어 성능이 ko-simcse보다 낮을 수 있음

#### multilingual-e5-small
- **장점**: 
  - 작은 메모리 사용량 (~10-15GB)
  - 다국어 지원
  - E5 시리즈 (검증된 아키텍처)
- **단점**: 
  - 한국어 성능이 ko-simcse보다 낮을 수 있음

### 5. 실험 전략

#### 단계 1: 작은 모델로 베이스라인 확립
1. ko-simcse로 다양한 하이퍼파라미터 탐색
2. 최적 하이퍼파라미터 조합 확인
3. 성능 베이스라인 확립

#### 단계 2: BGE-m3-ko 제한적 실험
1. 작은 배치 크기 (32, 64)와 시퀀스 길이 (256)로만 실험
2. 성공한 run만 분석
3. 최적 조합 확인

#### 단계 3: 성능 비교
1. 각 모델의 최고 성능 비교
2. 메모리 사용량 대비 성능 평가
3. 최종 모델 선택

### 6. 모니터링

WandB에서 다음을 확인:
1. **OOM 발생률**: 모델별 OOM 발생 빈도
2. **성공한 Run**: 각 모델의 성공한 run 수
3. **성능 메트릭**: 성공한 run의 성능 비교

### 7. 권장 접근 방법

1. **현재 Sweep 실행**: 모든 모델 포함하여 실행
2. **결과 분석**: WandB에서 모델별로 필터링하여 분석
3. **BGE-m3-ko 성공 케이스 확인**: 성공한 run의 하이퍼파라미터 확인
4. **추가 실험**: 성공한 조합 주변으로 추가 탐색

## 결론

- ✅ **모델 후보 확장 완료**: 4개 모델 추가
- ✅ **메모리 최적화 설정 완료**: Gradient Checkpointing + AMP
- 🔄 **BGE-m3-ko 사용 시**: 작은 배치 크기와 시퀀스 길이 권장
- 💡 **대안**: ko-simcse가 메모리 효율적이고 한국어 성능 우수

BGE-m3-ko는 성능이 좋지만 메모리 사용량이 크므로, 작은 모델로 먼저 실험하고 필요시 BGE-m3-ko를 제한적으로 사용하는 것을 권장합니다.

