#!/usr/bin/env bash
set -e

# Ï°∞Î¨∏, Ìï≠, Ìò∏ Îã®ÏúÑÎ°ú passage ÏÉùÏÑ± Î∞è pre-trained Î™®Îç∏ ÌèâÍ∞Ä Ïä§ÌÅ¨Î¶ΩÌä∏
# 
# ÏÇ¨Ïö©Î≤ï:
#   bash scripts/eval_chunk_units.sh
#   ÎòêÎäî
#   bash scripts/eval_chunk_units.sh --models jhgan/ko-sroberta-multitask dragonkue/BGE-m3-ko

# Í∏∞Î≥∏ ÏÑ§Ï†ï
LAW_SRC_DIR="${LAW_SRC_DIR:-data/laws}"
ADMIN_SRC_DIR="${ADMIN_SRC_DIR:-data/admin_rules}"
PREC_JSON_DIR="${PREC_JSON_DIR:-data/precedents}"
OUTPUT_BASE_DIR="${OUTPUT_BASE_DIR:-data/eval_chunk_units}"
EVAL_PAIRS="${EVAL_PAIRS:-data/processed/pairs_train_valid.jsonl}"

# ÌèâÍ∞ÄÌï† Î™®Îç∏Îì§ (Í∏∞Î≥∏Í∞í)
MODELS=("jhgan/ko-sroberta-multitask" "dragonkue/BGE-m3-ko")

# Ïª§Îß®ÎìúÎùºÏù∏ Ïù∏Ïûê ÌååÏã±
while [[ $# -gt 0 ]]; do
    case $1 in
        --models)
            shift
            MODELS=()
            while [[ $# -gt 0 ]] && [[ ! "$1" =~ ^-- ]]; do
                MODELS+=("$1")
                shift
            done
            ;;
        --law-src-dir)
            LAW_SRC_DIR="$2"
            shift 2
            ;;
        --admin-src-dir)
            ADMIN_SRC_DIR="$2"
            shift 2
            ;;
        --prec-json-dir)
            PREC_JSON_DIR="$2"
            shift 2
            ;;
        --output-dir)
            OUTPUT_BASE_DIR="$2"
            shift 2
            ;;
        --eval-pairs)
            EVAL_PAIRS="$2"
            shift 2
            ;;
        *)
            echo "Ïïå Ïàò ÏóÜÎäî ÏòµÏÖò: $1"
            echo "ÏÇ¨Ïö©Î≤ï: bash scripts/eval_chunk_units.sh [--models MODEL1 MODEL2 ...] [--law-src-dir DIR] [--output-dir DIR] [--eval-pairs FILE]"
            exit 1
            ;;
    esac
done

echo "=========================================="
echo "Passage Chunk Îã®ÏúÑÎ≥Ñ Pre-trained Î™®Îç∏ ÌèâÍ∞Ä"
echo "=========================================="
echo ""
echo "ÏÑ§Ï†ï:"
echo "  Î≤ïÎ†π ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨: $LAW_SRC_DIR"
echo "  ÌñâÏ†ïÍ∑úÏπô ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨: $ADMIN_SRC_DIR"
echo "  ÌåêÎ°Ä JSON ÎîîÎ†âÌÜ†Î¶¨: $PREC_JSON_DIR"
echo "  Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨: $OUTPUT_BASE_DIR"
echo "  ÌèâÍ∞Ä Ïåç ÌååÏùº: $EVAL_PAIRS"
echo "  ÌèâÍ∞Ä Î™®Îç∏: ${MODELS[@]}"
echo ""

# ÌèâÍ∞Ä Ïåç ÌååÏùº ÌôïÏù∏
if [ ! -f "$EVAL_PAIRS" ]; then
    echo "‚ö†Ô∏è  Í≤ΩÍ≥†: ÌèâÍ∞Ä Ïåç ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: $EVAL_PAIRS"
    echo "   Î®ºÏ†Ä make_pairsÎ•º Ïã§ÌñâÌïòÏó¨ ÌèâÍ∞Ä ÏåçÏùÑ ÏÉùÏÑ±ÌïòÏÑ∏Ïöî."
    exit 1
fi

# Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
mkdir -p "$OUTPUT_BASE_DIR"

# Í≤∞Í≥º Ï†ÄÏû•Ïö©
RESULTS_DIR="$OUTPUT_BASE_DIR/results"
mkdir -p "$RESULTS_DIR"

# ==========================================
# 1. Ìï≠ Îã®ÏúÑÎ°ú passage ÏÉùÏÑ± (Í∏∞Î≥∏Í∞í)
# ==========================================
echo "[1/6] Ìï≠ Îã®ÏúÑ passage ÏÉùÏÑ± Ï§ë..."
PARAGRAPH_DIR="$OUTPUT_BASE_DIR/paragraph"
mkdir -p "$PARAGRAPH_DIR"

poetry run python -m lex_dpr.data_processing.preprocess_auto \
    --src-dir "$ADMIN_SRC_DIR" \
    --out-admin "$PARAGRAPH_DIR/admin_passages.jsonl" \
    --glob "**/*.json" || true

poetry run python -m lex_dpr.data_processing.preprocess_auto \
    --src-dir "$LAW_SRC_DIR" \
    --out-law "$PARAGRAPH_DIR/law_passages.jsonl" \
    --glob "**/*.json" || true

# ÏΩîÌçºÏä§ Î≥ëÌï©
if [ -f "$PARAGRAPH_DIR/admin_passages.jsonl" ] && [ -f "$PARAGRAPH_DIR/law_passages.jsonl" ]; then
    poetry run python -m lex_dpr.data_processing.merge_corpus \
        --law "$PARAGRAPH_DIR/law_passages.jsonl" \
        --admin "$PARAGRAPH_DIR/admin_passages.jsonl" \
        --out "$PARAGRAPH_DIR/merged_corpus.jsonl"
elif [ -f "$PARAGRAPH_DIR/law_passages.jsonl" ]; then
    poetry run python -m lex_dpr.data_processing.merge_corpus \
        --law "$PARAGRAPH_DIR/law_passages.jsonl" \
        --out "$PARAGRAPH_DIR/merged_corpus.jsonl"
fi

echo "‚úÖ Ìï≠ Îã®ÏúÑ passage ÏÉùÏÑ± ÏôÑÎ£å: $PARAGRAPH_DIR/merged_corpus.jsonl"
echo ""

# ==========================================
# 2. Ìò∏ Îã®ÏúÑÎ°ú passage ÏÉùÏÑ±
# ==========================================
echo "[2/6] Ìò∏ Îã®ÏúÑ passage ÏÉùÏÑ± Ï§ë..."
ITEM_DIR="$OUTPUT_BASE_DIR/item"
mkdir -p "$ITEM_DIR"

poetry run python -m lex_dpr.data_processing.preprocess_auto \
    --src-dir "$ADMIN_SRC_DIR" \
    --out-admin "$ITEM_DIR/admin_passages.jsonl" \
    --glob "**/*.json" || true

poetry run python -m lex_dpr.data_processing.preprocess_auto \
    --src-dir "$LAW_SRC_DIR" \
    --out-law "$ITEM_DIR/law_passages.jsonl" \
    --include-items \
    --glob "**/*.json" || true

# ÏΩîÌçºÏä§ Î≥ëÌï©
if [ -f "$ITEM_DIR/admin_passages.jsonl" ] && [ -f "$ITEM_DIR/law_passages.jsonl" ]; then
    poetry run python -m lex_dpr.data_processing.merge_corpus \
        --law "$ITEM_DIR/law_passages.jsonl" \
        --admin "$ITEM_DIR/admin_passages.jsonl" \
        --out "$ITEM_DIR/merged_corpus.jsonl"
elif [ -f "$ITEM_DIR/law_passages.jsonl" ]; then
    poetry run python -m lex_dpr.data_processing.merge_corpus \
        --law "$ITEM_DIR/law_passages.jsonl" \
        --out "$ITEM_DIR/merged_corpus.jsonl"
fi

echo "‚úÖ Ìò∏ Îã®ÏúÑ passage ÏÉùÏÑ± ÏôÑÎ£å: $ITEM_DIR/merged_corpus.jsonl"
echo ""

# ==========================================
# 3. Ï°∞Î¨∏ Îã®ÏúÑÎ°ú passage ÏÉùÏÑ±
# ==========================================
echo "[3/6] Ï°∞Î¨∏ Îã®ÏúÑ passage ÏÉùÏÑ± Ï§ë..."
ARTICLE_DIR="$OUTPUT_BASE_DIR/article"
mkdir -p "$ARTICLE_DIR"

# Ï°∞Î¨∏ Îã®ÏúÑÎäî Ìï≠Ïù¥ ÏóÜÏùÑ ÎïåÎßå ÏÉùÏÑ±ÎêòÎØÄÎ°ú, Î≥ÑÎèÑ Ï≤òÎ¶¨
# ÌñâÏ†ïÍ∑úÏπôÏùÄ Ïù¥ÎØ∏ Ï°∞Î¨∏ Îã®ÏúÑÏù¥ÎØÄÎ°ú Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
poetry run python -m lex_dpr.data_processing.preprocess_auto \
    --src-dir "$ADMIN_SRC_DIR" \
    --out-admin "$ARTICLE_DIR/admin_passages.jsonl" \
    --glob "**/*.json" || true

# Î≤ïÎ†πÏùÄ Ï°∞Î¨∏ Îã®ÏúÑÎ°ú Í∞ïÏ†ú ÏÉùÏÑ±ÌïòÎäî Ïä§ÌÅ¨Î¶ΩÌä∏ ÌïÑÏöî
# ÏùºÎã® Ìï≠Ïù¥ ÏóÜÎäî Í≤ΩÏö∞Îßå Ìè¨Ìï® (Ïã§Ï†úÎ°úÎäî Ï°∞Î¨∏ Ï†ÑÏ≤¥Î•º Ìï©ÏπòÎäî Î°úÏßÅ ÌïÑÏöî)
poetry run python -m lex_dpr.data_processing.preprocess_auto \
    --src-dir "$LAW_SRC_DIR" \
    --out-law "$ARTICLE_DIR/law_passages.jsonl" \
    --glob "**/*.json" || true

# Ï°∞Î¨∏ Îã®ÏúÑÎ°ú Î≥ÄÌôòÌïòÎäî Python Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ
poetry run python -c "
from pathlib import Path
import json
from lex_dpr.utils.io import read_jsonl, write_jsonl

# Î≤ïÎ†π passageÎ•º Ï°∞Î¨∏ Îã®ÏúÑÎ°ú Î≥ëÌï©
law_passages = list(read_jsonl('$ARTICLE_DIR/law_passages.jsonl'))
article_dict = {}

for p in law_passages:
    article_key = p.get('article', '')
    if not article_key:
        continue
    
    if article_key not in article_dict:
        article_dict[article_key] = {
            'id': p.get('parent_id') or p.get('id'),
            'parent_id': p.get('parent_id') or p.get('id'),
            'type': p.get('type', 'Î≤ïÎ†π'),
            'law_id': p.get('law_id'),
            'law_name': p.get('law_name'),
            'article': article_key,
            'effective_date': p.get('effective_date'),
            'text': p.get('text', ''),
        }
    else:
        # Í∞ôÏùÄ Ï°∞Î¨∏Ïùò Îã§Î•∏ Ìï≠/Ìò∏Î•º Ìï©Ïπ®
        article_dict[article_key]['text'] += '\n' + p.get('text', '')

# Ï°∞Î¨∏ Îã®ÏúÑ passage Ï†ÄÏû•
article_passages = list(article_dict.values())
write_jsonl('$ARTICLE_DIR/law_passages_article.jsonl', article_passages)
print(f'Ï°∞Î¨∏ Îã®ÏúÑ passage ÏÉùÏÑ±: {len(article_passages)}Í∞ú')
"

# ÏΩîÌçºÏä§ Î≥ëÌï©
if [ -f "$ARTICLE_DIR/admin_passages.jsonl" ] && [ -f "$ARTICLE_DIR/law_passages_article.jsonl" ]; then
    poetry run python -m lex_dpr.data_processing.merge_corpus \
        --law "$ARTICLE_DIR/law_passages_article.jsonl" \
        --admin "$ARTICLE_DIR/admin_passages.jsonl" \
        --out "$ARTICLE_DIR/merged_corpus.jsonl"
elif [ -f "$ARTICLE_DIR/law_passages_article.jsonl" ]; then
    poetry run python -m lex_dpr.data_processing.merge_corpus \
        --law "$ARTICLE_DIR/law_passages_article.jsonl" \
        --out "$ARTICLE_DIR/merged_corpus.jsonl"
fi

echo "‚úÖ Ï°∞Î¨∏ Îã®ÏúÑ passage ÏÉùÏÑ± ÏôÑÎ£å: $ARTICLE_DIR/merged_corpus.jsonl"
echo ""

# ==========================================
# 4. Í∞Å chunk Îã®ÏúÑÎ≥ÑÎ°ú Î™®Îç∏ ÌèâÍ∞Ä
# ==========================================
echo "[4/6] Í∞Å chunk Îã®ÏúÑÎ≥Ñ Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë..."
echo ""

# ÌèâÍ∞Ä Í≤∞Í≥º ÏöîÏïΩ
SUMMARY_FILE="$RESULTS_DIR/summary.txt"
echo "Passage Chunk Îã®ÏúÑÎ≥Ñ Pre-trained Î™®Îç∏ ÌèâÍ∞Ä Í≤∞Í≥º" > "$SUMMARY_FILE"
echo "================================================" >> "$SUMMARY_FILE"
echo "" >> "$SUMMARY_FILE"
echo "ÌèâÍ∞Ä ÏùºÏãú: $(date)" >> "$SUMMARY_FILE"
echo "ÌèâÍ∞Ä Ïåç ÌååÏùº: $EVAL_PAIRS" >> "$SUMMARY_FILE"
echo "ÌèâÍ∞Ä Î™®Îç∏: ${MODELS[@]}" >> "$SUMMARY_FILE"
echo "" >> "$SUMMARY_FILE"

for CHUNK_TYPE in "paragraph" "item" "article"; do
    CHUNK_DIR="$OUTPUT_BASE_DIR/$CHUNK_TYPE"
    CORPUS_FILE="$CHUNK_DIR/merged_corpus.jsonl"
    
    if [ ! -f "$CORPUS_FILE" ]; then
        echo "‚ö†Ô∏è  Í≤ΩÍ≥†: $CORPUS_TYPE ÏΩîÌçºÏä§ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: $CORPUS_FILE"
        continue
    fi
    
    echo "----------------------------------------" >> "$SUMMARY_FILE"
    echo "Chunk Îã®ÏúÑ: $CHUNK_TYPE" >> "$SUMMARY_FILE"
    echo "----------------------------------------" >> "$SUMMARY_FILE"
    
    # Passage Í∞úÏàò ÌôïÏù∏
    PASSAGE_COUNT=$(poetry run python -c "from lex_dpr.utils.io import read_jsonl; print(len(list(read_jsonl('$CORPUS_FILE'))))")
    echo "Passage Í∞úÏàò: $PASSAGE_COUNT" >> "$SUMMARY_FILE"
    echo "" >> "$SUMMARY_FILE"
    
    for MODEL in "${MODELS[@]}"; do
        MODEL_NAME=$(echo "$MODEL" | sed 's/[\/\-]/_/g')
        RESULT_FILE="$RESULTS_DIR/${CHUNK_TYPE}_${MODEL_NAME}.json"
        REPORT_FILE="$RESULTS_DIR/${CHUNK_TYPE}_${MODEL_NAME}.txt"
        
        echo "  ÌèâÍ∞Ä Ï§ë: $CHUNK_TYPE / $MODEL"
        
        # ÌèâÍ∞Ä Ïã§Ìñâ
        poetry run lex-dpr eval \
            --model "$MODEL" \
            --corpus "$CORPUS_FILE" \
            --eval-pairs "$EVAL_PAIRS" \
            --output "$RESULT_FILE" \
            --report "$REPORT_FILE" \
            --k-values 1 3 5 10 20 \
            --batch-size 8 \
            --no-wandb || {
            echo "    ‚ö†Ô∏è  ÌèâÍ∞Ä Ïã§Ìå®: $MODEL"
            continue
        }
        
        # Í≤∞Í≥º ÏöîÏïΩ Ï∂îÏ∂ú
        if [ -f "$RESULT_FILE" ]; then
            echo "    Î™®Îç∏: $MODEL" >> "$SUMMARY_FILE"
            poetry run python -c "
import json
with open('$RESULT_FILE', 'r', encoding='utf-8') as f:
    results = json.load(f)
    for key in ['val_cosine_ndcg@10', 'val_cosine_recall@10', 'val_cosine_mrr@10']:
        if key in results:
            print(f'      {key}: {results[key]:.4f}')
" >> "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
        fi
    done
    echo "" >> "$SUMMARY_FILE"
done

# ==========================================
# 5. Í≤∞Í≥º ÎπÑÍµê Î∞è Ï∂úÎ†•
# ==========================================
echo "[5/6] Í≤∞Í≥º ÎπÑÍµê Ï§ë..."
echo ""

# ÎπÑÍµê ÌÖåÏù¥Î∏î ÏÉùÏÑ±
COMPARISON_FILE="$RESULTS_DIR/comparison.txt"
poetry run python << EOF
import json
from pathlib import Path

results_dir = Path("$RESULTS_DIR")
chunk_types = ["paragraph", "item", "article"]
models = ${MODELS[@]@Q}

comparison = {}
for chunk_type in chunk_types:
    comparison[chunk_type] = {}
    for model in models:
        model_name = model.replace("/", "_").replace("-", "_")
        result_file = results_dir / f"{chunk_type}_{model_name}.json"
        if result_file.exists():
            with open(result_file, 'r', encoding='utf-8') as f:
                results = json.load(f)
                comparison[chunk_type][model] = {
                    'ndcg@10': results.get('val_cosine_ndcg@10', 0),
                    'recall@10': results.get('val_cosine_recall@10', 0),
                    'mrr@10': results.get('val_cosine_mrr@10', 0),
                }

# ÎπÑÍµê ÌÖåÏù¥Î∏î Ï∂úÎ†•
with open("$COMPARISON_FILE", 'w', encoding='utf-8') as f:
    f.write("=" * 100 + "\n")
    f.write("Passage Chunk Îã®ÏúÑÎ≥Ñ Î™®Îç∏ ÏÑ±Îä• ÎπÑÍµê\n")
    f.write("=" * 100 + "\n\n")
    
    for model in models:
        f.write(f"\nÎ™®Îç∏: {model}\n")
        f.write("-" * 100 + "\n")
        f.write(f"{'Chunk Îã®ÏúÑ':<20} {'NDCG@10':<15} {'Recall@10':<15} {'MRR@10':<15}\n")
        f.write("-" * 100 + "\n")
        
        for chunk_type in chunk_types:
            if chunk_type in comparison and model in comparison[chunk_type]:
                metrics = comparison[chunk_type][model]
                f.write(f"{chunk_type:<20} {metrics['ndcg@10']:<15.4f} {metrics['recall@10']:<15.4f} {metrics['mrr@10']:<15.4f}\n")
        
        f.write("\n")

print("‚úÖ ÎπÑÍµê Í≤∞Í≥º Ï†ÄÏû•: $COMPARISON_FILE")
EOF

# ==========================================
# 6. ÏµúÏ¢Ö ÏöîÏïΩ Ï∂úÎ†•
# ==========================================
echo "[6/6] ÏµúÏ¢Ö ÏöîÏïΩ"
echo ""
echo "=========================================="
echo "ÌèâÍ∞Ä ÏôÑÎ£å!"
echo "=========================================="
echo ""
echo "üìä Í≤∞Í≥º ÌååÏùº:"
echo "  - ÏöîÏïΩ: $SUMMARY_FILE"
echo "  - ÎπÑÍµê: $COMPARISON_FILE"
echo ""
echo "üìÅ ÏÉÅÏÑ∏ Í≤∞Í≥º:"
for CHUNK_TYPE in "paragraph" "item" "article"; do
    for MODEL in "${MODELS[@]}"; do
        MODEL_NAME=$(echo "$MODEL" | sed 's/[\/\-]/_/g')
        RESULT_FILE="$RESULTS_DIR/${CHUNK_TYPE}_${MODEL_NAME}.json"
        REPORT_FILE="$RESULTS_DIR/${CHUNK_TYPE}_${MODEL_NAME}.txt"
        if [ -f "$RESULT_FILE" ]; then
            echo "  - $CHUNK_TYPE / $MODEL:"
            echo "    JSON: $RESULT_FILE"
            echo "    Î¶¨Ìè¨Ìä∏: $REPORT_FILE"
        fi
    done
done
echo ""
echo "üìà ÎπÑÍµê Í≤∞Í≥º ÎØ∏Î¶¨Î≥¥Í∏∞:"
cat "$COMPARISON_FILE"
echo ""
echo "=========================================="

