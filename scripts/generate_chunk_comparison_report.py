#!/usr/bin/env python3
"""
Chunk ë‹¨ìœ„ë³„ ì„±ëŠ¥ ë° í† í° ì ˆì•½ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

Article top-10 vs Paragraph top-10/20ì˜ ì„±ëŠ¥ê³¼ í† í° ì°¨ì´ë¥¼ ë¶„ì„í•˜ì—¬
ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    poetry run python scripts/generate_chunk_comparison_report.py \
        --eval-results-dir data/eval_chunk_units/results \
        --output-report data/eval_chunk_units/results/comprehensive_report.md
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime

from lex_dpr.utils.io import read_jsonl


def load_eval_results(results_dir: Path) -> Dict[str, Any]:
    """í‰ê°€ ê²°ê³¼ íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    results = {
        'model_info': {},
        'chunk_results': {},
        'token_stats': {},
        'token_savings': {}
    }
    
    # ëª¨ë¸ ì •ë³´ ë¡œë“œ
    model_info_file = results_dir / "model_info.json"
    if model_info_file.exists():
        with open(model_info_file, 'r', encoding='utf-8') as f:
            results['model_info'] = json.load(f)
    
    # í† í° í†µê³„ ë¡œë“œ
    token_stats_file = results_dir / "token_stats.json"
    if token_stats_file.exists():
        with open(token_stats_file, 'r', encoding='utf-8') as f:
            token_data = json.load(f)
            results['token_stats'] = token_data.get('token_stats', {})
            results['token_savings'] = token_data.get('token_savings', {})
    
    # Chunk ë‹¨ìœ„ë³„ í‰ê°€ ê²°ê³¼ ë¡œë“œ
    chunk_types = ["paragraph", "item", "article"]
    for chunk_type in chunk_types:
        results['chunk_results'][chunk_type] = {}
        
        # ê° ëª¨ë¸ë³„ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        for result_file in results_dir.glob(f"{chunk_type}_*.json"):
            model_name = result_file.stem.replace(f"{chunk_type}_", "").replace("_", "/")
            
            try:
                with open(result_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    metrics = data.get('metrics', data)
                    results['chunk_results'][chunk_type][model_name] = metrics
            except Exception as e:
                print(f"âš ï¸  ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({result_file}): {e}")
    
    return results


def calculate_llm_token_comparison(
    token_stats: Dict[str, Any],
    top_k_values: List[int] = [10, 20]
) -> Dict[str, Any]:
    """
    LLMì— ì „ë‹¬í•  ë•Œì˜ í† í° ë¹„êµ ê³„ì‚°
    
    Article top-10 vs Paragraph top-10/20ì˜ í† í° ìˆ˜ ë¹„êµ
    """
    comparison = {}
    
    article_stats = token_stats.get('article', {})
    paragraph_stats = token_stats.get('paragraph', {})
    
    article_avg_tokens = article_stats.get('avg_tokens', 0)
    paragraph_avg_tokens = paragraph_stats.get('avg_tokens', 0)
    
    for k in top_k_values:
        # Article top-k: kê°œì˜ article passage
        article_total_tokens = article_avg_tokens * k
        
        # Paragraph top-k: kê°œì˜ paragraph passage
        paragraph_total_tokens = paragraph_avg_tokens * k
        
        # ì ˆì•½ í† í° ë° ë¹„ìœ¨
        if article_total_tokens > 0:
            savings_tokens = article_total_tokens - paragraph_total_tokens
            savings_percentage = (savings_tokens / article_total_tokens) * 100
        else:
            savings_tokens = 0
            savings_percentage = 0
        
        comparison[f"top_{k}"] = {
            "article_tokens": article_total_tokens,
            "paragraph_tokens": paragraph_total_tokens,
            "savings_tokens": savings_tokens,
            "savings_percentage": savings_percentage
        }
    
    return comparison


def generate_markdown_report(
    results: Dict[str, Any],
    output_file: Path,
    top_k_values: List[int] = [10, 20]
) -> None:
    """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    lines = []
    lines.append("# Chunk ë‹¨ìœ„ë³„ ëª¨ë¸ ì„±ëŠ¥ ë° í† í° ì ˆì•½ ë¶„ì„ ë¦¬í¬íŠ¸")
    lines.append("")
    lines.append(f"**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # 1. ëª¨ë¸ ì •ë³´ ìš”ì•½
    lines.append("## 1. í‰ê°€ëœ ëª¨ë¸ ì •ë³´")
    lines.append("")
    lines.append("| ëª¨ë¸ | í¬ê¸° (M) | Max Length | Embedding Dim |")
    lines.append("|------|----------|------------|---------------|")
    
    model_info = results.get('model_info', {})
    for model_name, info in sorted(model_info.items()):
        size_str = f"{info.get('size_m', 'N/A')}M" if info.get('size_m') else "N/A"
        max_len = info.get('max_length', 'N/A')
        emb_dim = info.get('embedding_dim', 'N/A')
        lines.append(f"| {model_name} | {size_str} | {max_len} | {emb_dim} |")
    
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # 2. Chunk ë‹¨ìœ„ë³„ ì„±ëŠ¥ ë¹„êµ
    lines.append("## 2. Chunk ë‹¨ìœ„ë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    lines.append("")
    
    chunk_results = results.get('chunk_results', {})
    chunk_types = ["paragraph", "item", "article"]
    
    for chunk_type in chunk_types:
        if chunk_type not in chunk_results:
            continue
        
        lines.append(f"### 2.{chunk_types.index(chunk_type) + 1} {chunk_type.upper()} ë‹¨ìœ„")
        lines.append("")
        lines.append("| ëª¨ë¸ | NDCG@10 | Recall@10 | MRR@10 |")
        lines.append("|------|---------|-----------|--------|")
        
        # ì„±ëŠ¥ ìˆœìœ¼ë¡œ ì •ë ¬
        model_scores = []
        for model_name, metrics in chunk_results[chunk_type].items():
            ndcg = metrics.get('val_cosine_ndcg@10', 0)
            model_scores.append((model_name, metrics, ndcg))
        
        model_scores.sort(key=lambda x: x[2], reverse=True)
        
        for model_name, metrics, _ in model_scores:
            ndcg = metrics.get('val_cosine_ndcg@10', 0)
            recall = metrics.get('val_cosine_recall@10', 0)
            mrr = metrics.get('val_cosine_mrr@10', 0)
            lines.append(f"| {model_name} | {ndcg:.4f} | {recall:.4f} | {mrr:.4f} |")
        
        lines.append("")
    
    lines.append("---")
    lines.append("")
    
    # 3. í† í° í†µê³„
    lines.append("## 3. Chunk ë‹¨ìœ„ë³„ í† í° í†µê³„")
    lines.append("")
    
    token_stats = results.get('token_stats', {})
    if token_stats:
        lines.append("| Chunk ë‹¨ìœ„ | í‰ê·  í† í° ìˆ˜ | ì „ì²´ í† í° ìˆ˜ | Passage ê°œìˆ˜ |")
        lines.append("|------------|--------------|--------------|-------------|")
        
        for chunk_type in chunk_types:
            if chunk_type in token_stats:
                stats = token_stats[chunk_type]
                avg_tokens = stats.get('avg_tokens', 0)
                total_tokens = stats.get('total_tokens', 0)
                passage_count = stats.get('passage_count', 0)
                lines.append(f"| {chunk_type} | {avg_tokens:.1f} | {total_tokens:,} | {passage_count:,} |")
        
        lines.append("")
    
    lines.append("---")
    lines.append("")
    
    # 4. LLM ì „ë‹¬ ì‹œ í† í° ì ˆì•½ ë¶„ì„
    lines.append("## 4. LLM ì „ë‹¬ ì‹œ í† í° ì ˆì•½ ë¶„ì„")
    lines.append("")
    lines.append("Article top-k vs Paragraph top-kì˜ í† í° ìˆ˜ ë¹„êµ")
    lines.append("")
    
    llm_comparison = calculate_llm_token_comparison(token_stats, top_k_values)
    
    lines.append("| Top-K | Article í† í° | Paragraph í† í° | ì ˆì•½ í† í° | ì ˆì•½ìœ¨ |")
    lines.append("|-------|-------------|----------------|-----------|--------|")
    
    for k in top_k_values:
        comp = llm_comparison.get(f"top_{k}", {})
        article_tokens = comp.get('article_tokens', 0)
        paragraph_tokens = comp.get('paragraph_tokens', 0)
        savings_tokens = comp.get('savings_tokens', 0)
        savings_pct = comp.get('savings_percentage', 0)
        
        lines.append(f"| Top-{k} | {article_tokens:.1f} | {paragraph_tokens:.1f} | {savings_tokens:.1f} | {savings_pct:.1f}% |")
    
    lines.append("")
    lines.append("### 4.1 í† í° ì ˆì•½ íš¨ê³¼")
    lines.append("")
    
    for k in top_k_values:
        comp = llm_comparison.get(f"top_{k}", {})
        savings_pct = comp.get('savings_percentage', 0)
        savings_tokens = comp.get('savings_tokens', 0)
        
        lines.append(f"- **Top-{k}**: Article ëŒ€ë¹„ Paragraph ì‚¬ìš© ì‹œ **{savings_pct:.1f}%** ì ˆì•½ ({savings_tokens:.1f} í† í°)")
    
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # 5. ì„±ëŠ¥ vs í† í° ì ˆì•½ íŠ¸ë ˆì´ë“œì˜¤í”„
    lines.append("## 5. ì„±ëŠ¥ vs í† í° ì ˆì•½ íŠ¸ë ˆì´ë“œì˜¤í”„")
    lines.append("")
    
    # Articleê³¼ Paragraphì˜ ì„±ëŠ¥ ë¹„êµ
    if "article" in chunk_results and "paragraph" in chunk_results:
        lines.append("### 5.1 Article vs Paragraph ì„±ëŠ¥ ë¹„êµ")
        lines.append("")
        lines.append("| ëª¨ë¸ | Article NDCG@10 | Paragraph NDCG@10 | ì„±ëŠ¥ ì°¨ì´ |")
        lines.append("|------|-----------------|-------------------|-----------|")
        
        # ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ ë¹„êµ
        all_models = set()
        if "article" in chunk_results:
            all_models.update(chunk_results["article"].keys())
        if "paragraph" in chunk_results:
            all_models.update(chunk_results["paragraph"].keys())
        
        for model_name in sorted(all_models):
            article_ndcg = chunk_results.get("article", {}).get(model_name, {}).get('val_cosine_ndcg@10', 0)
            paragraph_ndcg = chunk_results.get("paragraph", {}).get(model_name, {}).get('val_cosine_ndcg@10', 0)
            diff = paragraph_ndcg - article_ndcg
            
            lines.append(f"| {model_name} | {article_ndcg:.4f} | {paragraph_ndcg:.4f} | {diff:+.4f} |")
        
        lines.append("")
        
        # í† í° ì ˆì•½ ì •ë³´ì™€ í•¨ê»˜ ìš”ì•½
        if "article_vs_paragraph" in results.get('token_savings', {}):
            savings_info = results['token_savings']['article_vs_paragraph']
            savings_pct = savings_info.get('savings_percentage', 0)
            
            lines.append(f"**ê²°ë¡ **: Paragraph ì‚¬ìš© ì‹œ í‰ê·  **{savings_pct:.1f}%** í† í° ì ˆì•½ì´ ê°€ëŠ¥í•˜ë©°, ")
            lines.append("ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì—ì„œ ì„±ëŠ¥ ì°¨ì´ëŠ” ë¯¸ë¯¸í•©ë‹ˆë‹¤.")
            lines.append("")
    
    lines.append("---")
    lines.append("")
    
    # 6. ê¶Œì¥ì‚¬í•­
    lines.append("## 6. ê¶Œì¥ì‚¬í•­")
    lines.append("")
    lines.append("### 6.1 Chunk ë‹¨ìœ„ ì„ íƒ")
    lines.append("")
    lines.append("- **Paragraph ë‹¨ìœ„**: í† í° ì ˆì•½ì´ ì¤‘ìš”í•˜ê³  ì„±ëŠ¥ ì €í•˜ë¥¼ ê°ìˆ˜í•  ìˆ˜ ìˆëŠ” ê²½ìš°")
    lines.append("- **Article ë‹¨ìœ„**: ìµœê³  ì„±ëŠ¥ì´ í•„ìš”í•œ ê²½ìš°")
    lines.append("- **Item ë‹¨ìœ„**: ì¤‘ê°„ ì„±ëŠ¥ê³¼ í† í° ì ˆì•½ì˜ ê· í˜•ì´ í•„ìš”í•œ ê²½ìš°")
    lines.append("")
    
    lines.append("### 6.2 Top-K ì„ íƒ")
    lines.append("")
    
    for k in top_k_values:
        comp = llm_comparison.get(f"top_{k}", {})
        savings_pct = comp.get('savings_percentage', 0)
        lines.append(f"- **Top-{k}**: {savings_pct:.1f}% í† í° ì ˆì•½")
    
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append(f"*ë¦¬í¬íŠ¸ ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
    
    # íŒŒì¼ ì €ì¥
    output_file.parent.mkdir(parents=True, exist_ok=True)
    output_file.write_text("\n".join(lines), encoding='utf-8')
    print(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description="Chunk ë‹¨ìœ„ë³„ ì„±ëŠ¥ ë° í† í° ì ˆì•½ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"
    )
    parser.add_argument(
        "--eval-results-dir",
        type=str,
        default="data/eval_chunk_units/results",
        help="í‰ê°€ ê²°ê³¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/eval_chunk_units/results)"
    )
    parser.add_argument(
        "--output-report",
        type=str,
        default="data/eval_chunk_units/results/comprehensive_report.md",
        help="ì¶œë ¥ ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: data/eval_chunk_units/results/comprehensive_report.md)"
    )
    parser.add_argument(
        "--top-k-values",
        nargs="+",
        type=int,
        default=[10, 20],
        help="ë¹„êµí•  Top-K ê°’ (ê¸°ë³¸ê°’: 10 20)"
    )
    
    args = parser.parse_args()
    
    results_dir = Path(args.eval_results_dir)
    output_file = Path(args.output_report)
    
    if not results_dir.exists():
        print(f"âŒ ì˜¤ë¥˜: í‰ê°€ ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_dir}")
        print("   ë¨¼ì € scripts/eval_chunk_units.pyë¥¼ ì‹¤í–‰í•˜ì—¬ í‰ê°€ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
        sys.exit(1)
    
    print("=" * 80)
    print("Chunk ë‹¨ìœ„ë³„ ì„±ëŠ¥ ë° í† í° ì ˆì•½ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
    print("=" * 80)
    print()
    print(f"í‰ê°€ ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
    print(f"ì¶œë ¥ ë¦¬í¬íŠ¸: {output_file}")
    print(f"Top-K ê°’: {args.top_k_values}")
    print()
    
    # ê²°ê³¼ ë¡œë“œ
    print("ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì¤‘...")
    results = load_eval_results(results_dir)
    
    if not results.get('chunk_results'):
        print("âš ï¸  ê²½ê³ : í‰ê°€ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € scripts/eval_chunk_units.pyë¥¼ ì‹¤í–‰í•˜ì—¬ í‰ê°€ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
        sys.exit(1)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    print("ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    generate_markdown_report(results, output_file, args.top_k_values)
    
    print()
    print("=" * 80)
    print("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
    print("=" * 80)
    print()
    print(f"ğŸ“„ ë¦¬í¬íŠ¸ íŒŒì¼: {output_file}")
    print()


if __name__ == "__main__":
    main()

